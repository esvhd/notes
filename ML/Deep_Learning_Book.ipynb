{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Notes\n",
    "\n",
    "Zhang Weiliang\n",
    "\n",
    "Creative Commons License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Backpropagation](#backprop)\n",
    "* [Batch Normalization](#batchnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential Formulae\n",
    "\n",
    "Definitions first:\n",
    "\n",
    "### Logistic Sigmoid\n",
    "\n",
    "$$ \\sigma(x) = \\frac{1}{1 + e^{-x}} $$\n",
    "\n",
    "The widespread of saturation of sigmoid function can make gradient-based learning very difficult. Thus their use as hidden units in feedforward networks is now **discouraged**.\n",
    "\n",
    "The use as output units is compatible with the use of gradient-based learning when an appropriate cost function can **undo** the saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11aeb4400>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkMpdRCQL/X/1v3/KLjr2TgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11adc0748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "n = np.linspace(-10, 10, 50)\n",
    "out = sigmoid(n)\n",
    "\n",
    "plt.plot(n, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softplus\n",
    "\n",
    "$$ \\zeta(x) = \\log(1 + e^x) $$\n",
    "\n",
    "The use as hidden units is **discouraged**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11abea2b0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aef2080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softplus(x):\n",
    "    return np.log(1 + np.exp(x))\n",
    "\n",
    "n = np.linspace(-10, 10, 50)\n",
    "out = softplus(n)\n",
    "\n",
    "plt.plot(n, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Sigmoid & Softplus functions\n",
    "Derivations for Page 67 formulae. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.33. \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sigma(x) =& \\frac{e^x}{e^x} \\times \\frac{1}{1 + e^{-x}} \\\\\n",
    "=& \\frac{e^x}{e^x(1 + e^{-x})} \\\\\n",
    "=& \\frac{e^x}{e^x + 1}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.34. \n",
    "\n",
    "Let $y = e^{-x}$, $z = 1 + y$, then we have $\\sigma(x) = z^{-1} $.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{d}{dx}\\sigma(x) =& \\frac{d\\sigma}{dz} \\times \\frac{dz}{dy} \\times \\frac{dy}{dx} \\\\\n",
    "=& -z^{-2} \\times 1 \\times -e^{-x} \\\\\n",
    "=& -(1 + e^{-1})^{-2} \\times -e^{-x} \\\\\n",
    "=& \\frac{e^{-x}}{(1 + e^{-1})^{2}} \\\\\n",
    "=& \\frac{1}{1 + e^{-1}} \\times \\frac{e^{-x}}{1 + e^{-1}} \\\\\n",
    "=& \\sigma(x) (1-\\sigma(x))\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.35.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "1 - \\sigma(x) =& 1 - \\frac{1}{1 + e^{-x}}\\\\\n",
    "=& \\frac{1 + e^{-x} - 1}{1 + e^{-x}} \\\\\n",
    "=& \\frac{e^{-x}}{1 + e^{-x}} \\\\\n",
    "=& \\frac{1}{e^x + 1} \\\\\n",
    "=& \\sigma(-x)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.36.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\log(\\sigma(x)) &= \\log\\big(\\frac{1}{1 + e^{-x}}\\big) \\\\\n",
    "&= \\log(1) - \\log(1 + e^{-x}) \\\\\n",
    "&= -\\log(1 + e^{-x}) \\\\\n",
    "&= -\\zeta(-x)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.37.\n",
    "\n",
    "Let $u = 1 + e^x$, hence $\\zeta(x) = \\log(u)$, then\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{d}{dx}\\zeta(x) =& \\frac{d\\zeta}{du} \\times \\frac{du}{dx} \\\\\n",
    "&= \\frac{1}{u} \\times e^x \\\\\n",
    "&= \\frac{e^x}{1 + e^x} \\\\\n",
    "&= \\frac{1}{e^{-x} + 1} \\\\\n",
    "&= \\sigma(x)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.38.\n",
    "\n",
    "**Logit function**, for $ \\forall x \\in (0, 1)$:\n",
    "\n",
    "$$ \\sigma^{-1}(x) = \\log\\bigg(\\frac{x}{1-x}\\bigg) $$\n",
    "\n",
    "Here the power of -1 does not mean reciprical, but the **inverse**. Eg. given $\\sigma(x)$, find $x$. \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sigma(x) &= \\frac{1}{1 + e^{-x}} \\\\\n",
    "1 + e^{-x} &= \\frac{1}{\\sigma(x)} \\\\\n",
    "e^{-x} &= \\frac{1}{\\sigma(x)} - 1 \\\\\n",
    "-x &= \\log\\bigg(\\frac{1-\\sigma(x)}{\\sigma(x)}\\bigg) \\\\\n",
    "x &= -\\log\\bigg(\\frac{1-\\sigma(x)}{\\sigma(x)}\\bigg) \\\\\n",
    "x &= \\log\\bigg(\\frac{\\sigma(x)}{1-\\sigma(x)}\\bigg)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40546510810816422"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logit(x):\n",
    "    return np.log(x / (1.-x))\n",
    "\n",
    "logit(.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59999999999999998"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(logit(.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.39.\n",
    "\n",
    "Inverse of $\\zeta(x)$, let $u=\\zeta(x)$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "u &= \\log(1 + e^x) \\\\\n",
    "e^u &= 1 + e^x \\\\\n",
    "e^x &= e^u - 1 \\\\\n",
    "\\forall x &> 0 \\text{, take log on both sides} \\\\\n",
    "x &= \\log\\big( e^u -1 \\big)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.40.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\int^{x}_{-\\infty} \\sigma(y)dy &= \\int^{x}_{-\\infty} \\frac{1}{1 + e^{-y}} \\\\\n",
    "&= \\log \\big \\lvert 1 + e^{-y} \\big \\rvert + y \\\\\n",
    "&= \\log \\big ( \\frac{e^y + 1}{e^y} \\big ) + y \\\\\n",
    "&= \\log(e^y + 1) - \\log(e^y) + y \\\\\n",
    "&= \\log(e^y + 1)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Key here is the integration part. Results can be checked with `SymPy`. Or, to reverse that back:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{d}{dx}\\big(\\log(1 + e^{-x}) + x\\big) &= \\frac{1}{1+e^{-x}} \\times -e^{-x} + 1 \\\\\n",
    "&= \\frac{1 + e^{-x} - e^{-x}}{1 + e^{-x}} \\\\\n",
    "&= \\sigma(x)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sympy as spy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y + log(1 + exp(-y))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = spy.Symbol('y')\n",
    "\n",
    "spy.integrate(1 / (1 + spy.exp(-y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp(-y)/(1 + exp(-y))**2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy.diff(1 / (1 + spy.exp(-y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 - exp(-y)/(1 + exp(-y))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy.diff(y + spy.log(1 + spy.exp(-y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.41\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\zeta(x)-\\zeta(-x) &= \\log(1 + e^x) - \\log(1 + e^{-x}) \\\\\n",
    "&= \\log\\bigg(\\frac{1 + e^x}{1 + e^{-x}}\\bigg) \\\\\n",
    "&= \\log\\bigg(\\frac{e^{-x}(1 + e^x)}{e^{-x}(1 + e^{-x})}\\bigg) \\\\\n",
    "&= \\log\\bigg(\\frac{e^{-x} + 1}{e^{-x}(1 + e^{-x})}\\bigg) \\\\\n",
    "&= \\log\\bigg(\\frac{1}{e^{-x}}\\bigg) \\\\\n",
    "&= \\log(e^x) \\\\\n",
    "&= x\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Derivatives\n",
    "\n",
    "**Product Rule**\n",
    "\n",
    "$$ (u \\cdot v)' = u' \\cdot v + u \\cdot v'$$\n",
    "\n",
    "** Quotient Rule**\n",
    "\n",
    "$$ \\bigg(\\frac{u}{v}\\bigg)' = \\frac{u'v - uv'}{v^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Function, p78\n",
    "\n",
    "$$ softmax(x)_i = \\frac{\\exp(x_i)}{\\sum_{j=1}^{n} \\exp(x_j)} $$\n",
    "\n",
    "Overflow when $x_i$ is very large, underflow when $x_i$ is very negative. Solution is to use $softmax(z)$, where:\n",
    "$z = x - max_i x_i$.\n",
    "\n",
    "**Derivative of Softmax**\n",
    "\n",
    "Using quotient rule, let $u=e^{x_i}$ and $v=\\sum_{j=1}^{n} e^{x_j}$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "u' &= e^{x_i} \\\\\n",
    "\\frac{\\partial v}{\\partial x_j} &= e^{x_j} \\\\\n",
    "S_i' = softmax'(x_i) &= \\frac{u'v - uv'}{v^2} \\\\\n",
    "&= \\frac{e^{x_i} \\cdot v - e^{x_i} e^{x_j}}{v^2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "When $i = j$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "S_i' = softmax'(x_i) &= \\frac{e^{x_i} \\cdot v - e^{x_i}e^{x_i}}{v^2} \\\\\n",
    "&= \\frac{e^{x_i} (v - e^{x_i})}{v^2} \\\\\n",
    "&= \\frac{e^{x_i}}{v} \\times \\frac{v - e^{x_i}}{v} \\\\\n",
    "&= S_i (1-S_i)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "When $i \\neq j$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial u}{\\partial x_j} &= 0 \\\\\n",
    "S_j' = softmax'(x_i) &=  \\frac{0 \\cdot v - e^{x_i}e^{x_j}}{v^2} \\\\\n",
    "&= -\\frac{e^{x_i}}{v}\\frac{e^{x_j}}{v} \\\\\n",
    "&= S_i S_j\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In terms of delta function:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta_{ij} &= \\begin{cases}\n",
    "1 & i=j\\\\\n",
    "0 & i\\neq j\n",
    "\\end{cases} \\\\\n",
    "S' &= S_i (\\delta_{ij} - S_j)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This is very similar to the derivative of sigmoid. Good [post](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/) on this topic.\n",
    "\n",
    "Typical softmax is used in a **Negative-Log-Likelihood (NLL)** loss function [Andrej's blog](http://cs231n.github.io/neural-networks-case-study/#grad):\n",
    "\n",
    "$$ L_i = -\\log S_i $$\n",
    "\n",
    "Therefore in backprop:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L_i}{\\partial S_i} &= - 1/S_i \\\\\n",
    "\\frac{\\partial S_i}{\\partial x_i} &= S_i(\\delta_{ij} - S_j) \\\\\n",
    "\\frac{\\partial L_i}{\\partial x_i} &= -\\frac{1}{S_i} \\times S_i(\\delta_{ij} - S_j) \\\\\n",
    "&= S_j - \\delta_{ij}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poor Conditioning\n",
    "\n",
    "Given function $f(x) = A^{-1}x$. When $A \\in \\mathbb{R}^{n \\times n}$ has an **eigenvalue decomposition**, its **condition number** is:\n",
    "\n",
    "$$ \\max_{i,j} \\bigg \\lvert \\frac{\\lambda_i}{\\lambda_j} \\bigg \\rvert $$\n",
    "\n",
    "I.e. Ratio of largest and smallest eigenvalues.\n",
    "\n",
    "Poor conditioning makes choosing a good optimization step size difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian Matrix & Min/Max/Saddle Points\n",
    "\n",
    "At a **critical point** where $\\triangledown_x f(x) = 0$:\n",
    "\n",
    "* **Local minimum** if the Hessian matrix is **positive definite** (i.e. all of its eigenvalues are positive).\n",
    "* **local maximum** if the Hessian matrix is **negative definite** (i.e. all of its eigenvalues are negative).\n",
    "* **Inconclusive** if all non-zero eigenvalues have the same sign but **at least one eigenvalue is zero**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 5\n",
    "\n",
    "**Representational Capacity**, p110, The model specifis which family of functions the learning algorithm can choose from when varying the parameters in order to reduce a training objective. \n",
    "\n",
    "**Effective Capacity** can be limited by imperfections of the optimization algorithm, which means it may be less than the representational capacity.\n",
    "\n",
    "## Vapnik-Chervonenkis (VC) Dimension, p111\n",
    "\n",
    "VC dimension measres the capacity of a binary classifier. Defined as being the lagest possible value of $m$ for which there exists a training set of $m$ different $x$ points that the classifier can label arbitrarily.\n",
    "\n",
    "The most important results in statistical learning theory show that the discrepancy between the trainnig error and generalization error is bounded from above by a quantity that grows as the model capacity grows but shrinks as the number of traning examples increase. \n",
    "\n",
    "However, this is rarely used in practice when working with deep learning algos. Because:\n",
    "* it can be quite difficult to determine the capacity of deal learning algos.\n",
    "* The problem of determining the capacity of deep learning models is especially difficult because the effective capacity is limited by the capabilities of the optimization algorithm. \n",
    "* we have little theoretical understanding of the general non-convex optimization problems involved in deep learning.\n",
    "\n",
    "Typically training error decreases until it asymptotes to the minimum possible error value as model capacity increases (assuming the error measure has a minimum value); generalization error typically has a U-shaped curve as a function of model capacity.\n",
    "\n",
    "**No Free Lunch theorem**: averaged over all possible data-generating distributions, every classification algothrim has the same error rate when classifying previously unobserved points. \n",
    "\n",
    "**Goal** is to understand what kind of distributions are relevant to the real world that an AI agent experiences, and what kind of machine learning algorithem perform well on data drawn from the kinds of data-generating distributions we care about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator, Bias and Variance\n",
    "\n",
    "Sample variance, unbiased sample variance, both underestimates the true standard deviation but are still used in practice. Unbiased sample variance is less of an underestimate. For large sample size $m$, the approximation is quite reasonable.\n",
    "\n",
    "## Maximum Likelihood Estimation\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\theta_{ML} &= \\underset{\\theta}{\\operatorname{arg max}} p_{model}(\\mathbb{X}; \\theta) \\\\\n",
    "&= \\underset{\\theta}{\\operatorname{arg max}}\\Pi_{i=1}^{m}p_{model}(x^{(i)}; \\theta) \\\\\n",
    "&= \\underset{\\theta}{\\operatorname{arg max}}\\sum_{i=1}^m \\log p_{model}(x^{(i)}; \\theta) \\\\\n",
    "D_{KL}(\\hat{p}_{data} \\lVert p_{model}) &= \\mathbb{E}_{x \\sim \\hat{p}_{data}} \\bigg[ \\log \\hat{p}_{data}(x) - \\log p_{model}(x)\\bigg] \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore minimizing KL divergence corresponds exactly to minimzing the cross-entropy between the distributions.\n",
    "\n",
    "**Appropriate Conditions** for maximum likelihood estimator to have the property of **consistency**:\n",
    "\n",
    "* The true distribution $p_{data}$ must lie within the model family $p_{model}(.;\\theta)$, otherwise, no estimator can recover $p_{data}$.\n",
    "\n",
    "* The true distribution $p_{data}$ must corresond to example one value of $\\theta$. Otherwise maximum likelihood can recover the correct $p_{data}$ but will not be able to determine which value of $\\theta$ was used by the data-generating process.\n",
    "\n",
    "For large sample size $m$, the **Cramer-Rao lower bound** shows that no consistent estimator has a lower Mean Square Error than the maximum likelihood estimator.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear Regression as Maximum Likelihood, p130\n",
    "\n",
    "Univariate Gaussian PDF:\n",
    "\n",
    "$$ PDF(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\bigg(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\bigg) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more efficient way to compute this is to define $\\beta$, called **precision = inverse of variance**.\n",
    "\n",
    "$$ PDF(x) = \\sqrt{\\frac{\\beta}{2\\pi}} \\exp\\bigg(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\bigg) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate Gaussian PDF:\n",
    "\n",
    "$$ \\mathcal{N}(x; \\mu, \\Sigma) = \\sqrt{\\frac{1}{(2\\pi)^n \\det(\\Sigma)}} \\exp\\bigg( -\\frac{1}{2} (x-\\mu)^T \\Sigma^{-1} (x-\\mu) \\bigg) $$\n",
    "\n",
    "Where $\\Sigma$ is a **positive definite** symmetric matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice when this needs to be evaluated many times, we instead use a **precision matrix** $\\beta = \\Sigma^{-1}$:\n",
    "\n",
    "$$ \\mathcal{N}(x; \\mu, \\Sigma) = \\sqrt{\\frac{\\det(\\beta)}{(2\\pi)^n}} \\exp\\bigg( -\\frac{1}{2} (x-\\mu)^T \\Sigma^{-1} (x-\\mu) \\bigg) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional log-likelihood derivation:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\sum_{i=1}^{m}\\log p(y^{(i)} \\mid x^{(i)};\\theta) \\\\\n",
    "=&\\sum_{i=1}^{m}\\log\\bigg[\\big(2\\pi\\sigma^2\\big)^{-1/2}\\exp\\bigg(-\\frac{\\lVert\\hat{y}^{(i)}-y^{(i)}\\rVert^2}{2\\sigma^2}\\bigg)\\bigg] \\\\\n",
    "=& \\sum_{i=1}^{m}\\bigg\\{-\\frac{1}{2}\\log\\big(2\\pi\\sigma^2\\big) + \\log\\bigg[\\exp\\bigg(-\\frac{\\lVert\\hat{y}^{(i)}-y^{(i)}\\rVert^2}{2\\sigma^2}\\bigg)\\bigg]\\bigg\\} \\\\\n",
    "=&\\sum_{i=1}^{m}\\bigg(-\\frac{1}{2}\\log\\big(2\\pi\\sigma^2\\big)\\bigg) - \\sum_{i=1}^{m}\\frac{\\lVert\\hat{y}^{(i)}-y^{(i)}\\rVert^2}{2\\sigma^2} \\\\\n",
    "=& -\\frac{m}{2}\\log\\big( 2\\pi \\big) - m\\log\\sigma - \\sum_{i=1}^{m}\\frac{\\lVert\\hat{y}^{(i)}-y^{(i)}\\rVert^2}{2\\sigma^2} \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Regression, p134\n",
    "\n",
    "Likelihood:\n",
    "\n",
    "$$ p(y \\mid X, w) \\propto \\exp\\bigg[-\\frac{1}{2}\\big(y-Xw\\big)^T \\big(y-Xw\\big)\\bigg] $$\n",
    "\n",
    "Prior:\n",
    "\n",
    "$$ p(w) \\propto \\exp\\bigg[ -\\frac{1}{2}(w-\\mu_0)^T\\Lambda^{-1}_{0}(w-\\mu_0) \\bigg] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(w \\mid X, y) &\\propto p(y \\mid X, w)p(w) \\\\\n",
    "&\\propto \\exp\\bigg[-\\frac{1}{2}\\big(y-Xw\\big)^T \\big(y-Xw\\big)\\bigg] \\exp\\bigg[ -\\frac{1}{2}(w-\\mu_0)^T\\Lambda^{-1}_{0}(w-\\mu_0)\\bigg] \\\\\n",
    "&\\propto \\exp\\bigg\\{ -\\frac{1}{2} \\bigg[ y^Ty - y^TXw - w^T X^T y + w^T X^T X w  + w^T \\Lambda^{-1}_{0}w - w^T\\Lambda^{-1}_{0}\\mu_0 -\\mu^T_0 \\Lambda^{-1}_{0}w + \\mu^T_0 \\Lambda^{-1}_{0}\\mu_0 \\bigg] \\bigg\\} \\\\\n",
    "\\because &\\text{ } y^TXw = w^T X^T y,\\text{ } \\mu^T_0 \\Lambda^{-1}_{0} w = w^T \\Lambda^{-1}_{0}\\mu_0 \\\\\n",
    "\\because &\\text{ terms without } w \\text{ can be ignored} \\\\\n",
    "&\\propto \\exp\\bigg\\{ -\\frac{1}{2} \\bigg[-2y^TXw + w^T X^T X w  + w^T \\Lambda^{-1}_{0}w - 2\\mu^T_0 \\Lambda^{-1}_{0}w \\bigg] \\bigg\\} \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Lambda_m &= \\big(X^T X + \\Lambda^{-1}_0\\big)^{-1} \\\\\n",
    "\\mu_m &= \\Lambda_m \\big(X^T y + \\Lambda^{-1}_0 \\mu_0\\big) \\\\\n",
    "& \\therefore \\\\\n",
    "\\mu^T_m &= \\big(X^T y + \\Lambda^{-1}_0\\mu_0\\big)^T \\Lambda^T_m  \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Also note $\\Lambda^T_m = \\Lambda_m$ as $\\Lambda_m = diag(\\lambda_m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite posterior:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(w \\mid X, y) &\\propto \\exp\\bigg(-\\frac{1}{2}\\big(w - \\mu_m\\big)^T \\Lambda^{-1}_m \\big(w - \\mu_m\\big)\\bigg) \\\\\n",
    "&\\propto \\exp\\bigg\\{-\\frac{1}{2}\\bigg[ w^T\\big(X^T X + \\Lambda^{-1}_0\\big)w - w^T\\Lambda^{-1}_m\\Lambda_m \\big(X^T y + \\Lambda^{-1}_0\\mu_0 \\big) -\\big(X^T y + \\Lambda^{-1}_0\\mu_0 \\big)^T\\Lambda^T_m\\Lambda^{-1}_m w \\bigg]\\bigg\\} \\\\\n",
    "&\\propto \\exp\\bigg\\{-\\frac{1}{2}\\bigg[ w^T X^T X w + w^T \\Lambda^{-1}_0 w - w^T X^T y - w^T \\Lambda^{-1}_0\\mu_0 - y^T Xw - \\mu^T_0 \\Lambda^{-1}_0 w \\bigg]\\bigg\\} \\\\\n",
    "&\\propto \\exp\\bigg\\{-\\frac{1}{2}\\bigg[ w^T X^T X w + w^T \\Lambda^{-1}_0 w - 2 y^T Xw - 2 \\mu^T_0 \\Lambda^{-1}_0 w \\bigg]\\bigg\\}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set $\\mu_0 = 0$, $\\Lambda_0 = \\frac{1}{\\alpha} I$, flat prior for covariance:\n",
    "\n",
    "$$ p(w \\mid X, y) \\propto \\exp\\bigg\\{-\\frac{1}{2}\\bigg[ w^T X^T X w + w^T \\alpha I w - 2 y^T X w \\bigg]\\bigg\\} $$\n",
    "\n",
    "This is the form of **ridge regression**, weight decay term $\\alpha w^T w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Algorithms\n",
    "\n",
    "### K-Nearest Neighbour\n",
    "* k-nearest neighbour can achieve high capacity. Enables it to obtain high accuracy given a large training set.\n",
    "* this comes with computational costs\n",
    "* may generalize very badly given a small training set. \n",
    "* It cannot learn that one feature is more discriminative than another.\n",
    "* Cannot solve a problem where $X\\in\\mathbb{R}^{100}$ but only $x_1$ is relavent to the output. \n",
    "\n",
    "### Decision Trees\n",
    "\n",
    "It struggles to solve some problems that are easy even for logistic regression, E.g. a 2-class problem and the positive class occurs whenever $x_2 > x_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning Algorithms\n",
    "\n",
    "Most comment representations:\n",
    "1. lower-dimensional representation,\n",
    "2. sparse representation (increase dimension),\n",
    "3. independent representation.\n",
    "\n",
    "### PCA\n",
    "\n",
    "Given design matrix $X$, centered with $\\mathbb{E}(x)=0$.\n",
    "\n",
    "Unbiased Sample Covariance associated with X is:\n",
    "\n",
    "$$ Var(x) = \\frac{1}{m-1}X^T X $$\n",
    "\n",
    "PCA finds a representation (through orghogonal, linear transformations) $z=W^T x$ where $Var(z)$ is diagonal (implies zero covariance of $z$).\n",
    "\n",
    "Two ways to find the Principal Components, $W$:\n",
    "\n",
    "* With Eigenvalue Decomposition: $X^T X = W \\Lambda W^T$\n",
    "\n",
    "* With SVD: $X=U \\Sigma W^T$, the **principal components** are the right singular vectors of $X$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X^T X &= (U \\Sigma W^T)^T U \\Sigma W^T \\\\\n",
    "&= W\\Sigma^T U^T U \\Sigma W^T \\\\\n",
    "\\because U \\text{ is orthogonal, } U^T U &= I \\\\\n",
    "X^T X &= W \\Sigma^2 W^T\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We can show $Var(z)$ is diagonal:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Z &= XW \\\\\n",
    "Var(z) &= \\frac{1}{m-1} Z^T Z \\\\\n",
    "&= \\frac{1}{m-1} (XW)^T X W \\\\\n",
    "&= \\frac{1}{m-1} W^T X^T X W \\\\\n",
    "\\because X^T X &= W \\Sigma^2 W^T \\\\\n",
    "Var(z) &= W^T W \\Sigma^2 W^T W \\\\\n",
    "\\because W^T W = I \\\\\n",
    "Var(z) &= \\Sigma^2 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent - Andrew Ng\n",
    "\n",
    "[videos](https://www.coursera.org/learn/machine-learning/home/week/10)\n",
    "\n",
    "### Batch Gradient Descent\n",
    "\n",
    "Goes through full dataset to perform one gradient update.\n",
    "\n",
    "Given cost function:\n",
    "\n",
    "$$ J_{train}(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m \\big(h_{\\theta}\\big(x^{(i)}\\big) - y^{(i)}\\big)^2 $$\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "```\n",
    "Repeat {\n",
    "```\n",
    "(for every $j = 0, \\dots, n$)\n",
    "\n",
    "$$\\theta_j = \\theta_j - \\alpha \\frac{1}{m}\\big(h_{\\theta}\\big(x^{(i)}\\big) - y^{(i)}\\big) x^{(i)}$$\n",
    "\n",
    "```\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD\n",
    "\n",
    "Updates gradient with each piece of training data (randomly shuffled). No summation in the update line.\n",
    "\n",
    "Will circle around the global minimum, but may not reach / stablize there.\n",
    "\n",
    "$$ J_{train}(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m \\big(h_{\\theta}\\big(x^{(i)}\\big) - y^{(i)}\\big)^2 $$\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "```\n",
    "Randomly shuffle dataset.\n",
    "\n",
    "Repeat { \\\\ for 1 - 10x \n",
    "```\n",
    "for $i = 1, \\dots, m$: \n",
    "\n",
    "(for every $j = 0, \\dots, n$)\n",
    "\n",
    "$$\\theta_j = \\theta_j - \\alpha \\big(h_{\\theta}\\big(x^{(i)}\\big) - y^{(i)}\\big) x^{(i)}$$\n",
    "\n",
    "```\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatch SGD\n",
    "\n",
    "Use a small subset $b$ of the training data for each gradient update. E.g. $b=10$ in each iteration. Update for gradient is the learning rate times average loss over the minibatch. \n",
    "\n",
    "$$\\theta_j = \\theta_j - \\alpha \\frac{1}{b} \\sum_{k=i}^{i+b}\\big(h_{\\theta}\\big(x^{(i)}\\big) - y^{(i)}\\big) x^{(i)}$$\n",
    "\n",
    "Runs faster when vectorized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence\n",
    "\n",
    "SGD:\n",
    "\n",
    "During learning, compute cost function, $cost(\\theta, (x^{(i)}, y^{(i)}))$ before updating $\\theta$.\n",
    "\n",
    "For every 1000 iterations, plot $cost(\\theta, (x^{(i)}, y^{(i)}))$ averaged over the last 1000 training data points processed by algorithm. \n",
    "\n",
    "Could decrease $\\alpha$ over time if we want $\\theta$ to converge. E.g. \n",
    "\n",
    "$$ \\alpha = \\frac{const1}{iterationNumber + const2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibatch SGD - DL Book\n",
    "\n",
    "Uses **minibatch** of $m'$, typically $m'$ ranges from 1 to a few 100s. Crucially, $m'$ is usually held fixed as the training set size $m$ grows.\n",
    "\n",
    "The number of updates required to reach convergence usually increases with training set size. However, as $m$ approaches infinity, the model will eventually converge to its best possible test error before SGD has sampled every sample in the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Algo Building Blocks:\n",
    "\n",
    "Four pieces:\n",
    "1. dataset\n",
    "2. cost function\n",
    "3. optimization procedure\n",
    "4. model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Constancy & Smoothness Regularization\n",
    "\n",
    "**Smoothness prior** or **local constancy prior** states that the function we learn should not change very much within a small region.\n",
    "\n",
    "Relying on this assumption alone fails to solve many deep learning problems. k-means and decision treess all suffer from this problem.\n",
    "\n",
    "In general, to distinguish $O(k)$ regions in input space, all these methods require $O(k)$ examples. Typically, there are $O(k)$ parameters, with $O(1)$ parameters associated with each of the $O(k)$ regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifold Learning\n",
    "\n",
    "In machine learning, manifold is loosely used to designate a connected set of points that can be approximated well by considering only a small number of degrees of freedom, or dimensions, embedded in a higher-dimensional space. Each direction corresponds to a direction of variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Based Learning\n",
    "\n",
    "For **feedforward neural nets**, it is important to initialize all weights to **small random numbers**. The biases may be initialized to **zero or to small positive values**. p172.\n",
    "\n",
    "Unfortunately mean square error and mean absolute error often lead to poor results when used with gradient-based optimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Output Unit for Bernoulli Output Distribution\n",
    "\n",
    "Sigmoid output unit is defined by:\n",
    "\n",
    "$$ \\hat{y} = \\sigma\\big(w^T h + b\\big) $$\n",
    "\n",
    "where $\\sigma$ is the logisitc sigmod function, $\\hat{y}$ is a scaler. In this case set $z = w^T h + b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Units for Multinoulli Output Distribution\n",
    "\n",
    "In this case the model output $\\hat{y}$ is a vector, of the following properties:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\forall i, y_i &\\in [0, 1] \\\\\n",
    "\\sum_i y &= 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Softmax Function\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "\\text{softmax}(z)_i &= \\frac{\\exp(z_i)}{\\sum_j \\exp(z_j)} \\\\\n",
    "\\log \\text{ softmax}(z)_i &= z_i - \\log\\sum_j \\exp(z_j) \\\\\n",
    "\\text{softmax}(z) &= \\text{softmax}(z - max_i z_i) \\text{, this is numerically stable}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$z$ is defined as:\n",
    "\n",
    "$$ z = W^T h + b $$\n",
    "\n",
    "where $W$ is a **matrix**, as oppose to $w$ being a **vector** in the Bernooulli case.\n",
    "\n",
    "Note that log-softmax **cannot saturate**.\n",
    "\n",
    "The log-likelihood term $\\log\\sum_j \\exp(z_j)$ can be roughly approximated as $\\max_j z_j$. p180. Therefore the intuition is that the negative log-likelihood cost funciton always strongly penalizes the most active incorrect prediction. \n",
    "\n",
    "Softmax function can saturate when the difference between input values become extreme. p180. Numerically stable softmax uses the above $\\max_j z_j$ approximation. If the cost function is not designed to undo the effects of softmax, it would also saturate when softmax saturates, in which case the gradient vanishes.\n",
    "\n",
    "In simple form, have $n$ outputs is an **overparameterization**, since $\\hat{y}$ sums to 1, we only need to know $n-1$ values. In practice, overparameterization rarely causes much difference and is simpler to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logsoftmax(z, i):\n",
    "    log_total = np.log(np.sum(np.exp(z)))\n",
    "    return z[i] - log_total\n",
    "\n",
    "def softmax(z, i):\n",
    "    '''\n",
    "    Numerically stable softmax.\n",
    "    '''\n",
    "    max_z = np.max(z)\n",
    "    z_mod = z - max_z\n",
    "    top = np.exp(z_mod[i])\n",
    "    bottom = np.sum(np.exp(z_mod))\n",
    "    return top / bottom\n",
    "\n",
    "def softmax_unstable(z, i):\n",
    "    top = np.exp(z[i])\n",
    "    bottom = np.sum(np.exp(z))\n",
    "    return top / bottom\n",
    "\n",
    "z = np.zeros(10)\n",
    "z[0] = 10000\n",
    "z[1] = 1\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zwl/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:16: RuntimeWarning: overflow encountered in exp\n",
      "/Users/zwl/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:17: RuntimeWarning: overflow encountered in exp\n",
      "/Users/zwl/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:18: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# this version has overflow problem\n",
    "print(softmax_unstable(z, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# this version performs well.\n",
    "print(softmax(z, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU, Rectified Linear Unit\n",
    "\n",
    "Activation function defined as:\n",
    "\n",
    "$$ g(z) = \\max\\{0, z\\} $$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial g}{\\partial z} &= \n",
    "\\begin{cases}\n",
    "0, z \\leq 0 \\\\\n",
    "1, z \\gt 0\n",
    "\\end{cases}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Benefits\n",
    "\n",
    "* when the unit is active, the gradient is not only large but also consistent.\n",
    "* second derivative is 0 almost everywhere. No second order effect.\n",
    "\n",
    "### Drawback\n",
    "\n",
    "Cannot learn via gradient-based methods on examples for which their activation is zero. Generalizations deals with this issue.\n",
    "\n",
    "### Generalizations, p187\n",
    "\n",
    "Based on using a nonzero slope $\\alpha$:\n",
    "\n",
    "$$ h_i = g(z, \\alpha)_i = \\max(0, z_i) + \\alpha_i \\min(0, z_i) $$\n",
    "\n",
    "Three types:\n",
    "\n",
    "* Absolute value rectification, fixes $\\alpha_i = -1$ to obtain $g(z) = |z|$,\n",
    "* Leaky ReLU, fixes $\\alpha$ to a small value like 0.01,\n",
    "* Parametric ReLU (PReLU) treats $\\alpha$ as a learnable parameter.\n",
    "* Maxout units: Learning the activation function itself, divides $z$ into groups of $k$ values, each maxout unit then outputs the maximum of one of these groups:\n",
    "\n",
    "$$ g(z)_i = \\max_{j \\in \\mathbb{G}^{(i)}} z_i $$\n",
    "\n",
    "\n",
    "### Maxout units:\n",
    "\n",
    "* provides a way of learning a piecewise linear function that responds to multiple-directions in the input $x$ space.\n",
    "* typically needs more regularization. can work well without regularization if traning set is large and no. of pieces per unit is kept low.\n",
    "* less parameters, next layer can get by with $k$ times fewer weights\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Redial Basis Function (RBF) as hidden unit\n",
    "\n",
    "$$ h_i = \\exp\\bigg(-\\frac{1}{\\sigma^2_i} \\| W_{:,i} - x \\|^2\\bigg) $$\n",
    "\n",
    "It becomes more active when $x$ approaches a template $W_{:,i}$. Saturates at 0 for most $x$, can be difficult to optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "For chain-based architectures, main consideration are choosing width of each layer and depth of the network.\n",
    "\n",
    "Deeper networks are often able to use far fewer units per layer and far fewer parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='backprop'></a>\n",
    "## Backpropation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source: Chris Olah's [blog](http://colah.github.io/posts/2015-08-Backprop/)\n",
    "\n",
    "For example in a graph with input $X$ and output $Z$.\n",
    "\n",
    "**Forward-mode** differentiation tracks how **one input** affects **every node** in a computational graph, i.e. $\\frac{\\partial}{\\partial X}$\n",
    "\n",
    "**Reverse-mode** differentiation tracks how **every node** in a computational graph affects **one output**, i.e. $\\frac{\\partial Z}{\\partial}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading: Michael Nielson's book [Chapter 2](http://neuralnetworksanddeeplearning.com/chap2.html)\n",
    "\n",
    "Notation: $w^l_{jk}$ - weight for the edge between the $k^{th}$ neuron in layter $(l-1)$ and the $j^{th}$ neuron in the layer $l$\n",
    "\n",
    "Assuming activation is done with the sigma function, we have:\n",
    "\n",
    "$$ a^l_j = \\sigma\\bigg(\\sum_k w^l_{jk} a^{(l-1)}_k + b^l_j \\bigg) $$\n",
    "\n",
    "In vector format, this simplifies to:\n",
    "\n",
    "$$ a^l = \\sigma\\bigg(w^l a^{(l-1)} + b^l \\bigg) $$\n",
    "\n",
    "Define **weighted input**, $z^l = w^l a^{(l-1)} + b^l$, we have $a^l = \\sigma(z^l)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Equations for Backprop\n",
    "\n",
    "Let $C$ be the cost function. Define error $\\delta^l_j$ of neuron $j$ in layer $l$:\n",
    "\n",
    "$$ \\delta^l_j = \\frac{\\partial C}{\\partial z^l_j} $$\n",
    "\n",
    "** Equation for the error in the Output Layer**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta^L_j &= \\frac{\\partial C}{\\partial z^L_j} \\\\\n",
    "&= \\frac{\\partial C}{\\partial a^L_j}\\frac{\\partial a^L_j}{\\partial z^L_j} \\\\\n",
    "&= \\frac{\\partial C}{\\partial a^L_j} \\sigma'\\big(z^L_j\\big) \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Equation for the error $\\sigma^l$ in terms of error in the next layer $\\sigma^{(l+1)}$** \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta^l &= \\bigg(\\big(w^{(l+1)}\\big)^T \\delta^{(l+1)}\\bigg) \\odot \\sigma'\\big(z^l\\big) \\\\\n",
    "&= \\frac{\\partial C}{\\partial z^l_j} \\\\\n",
    "&= \\sum_k \\frac{\\partial C}{\\partial z^{(l+1)}_j} \\frac{\\partial z^{(l+1)}_j}{\\partial z^l_j} \\\\\n",
    "&= \\sum_k \\frac{\\partial z^{(l+1)}_j}{\\partial z^l_j} \\delta^{(l+1)}_k \\\\\n",
    "\\because z^{(l+1)} &= w^{(l+1)} a^l + b^{(l+1)} \\\\\n",
    "z^{(l+1)} &= w^{(l+1)} \\sigma(z^l) + b^{(l+1)} \\\\\n",
    "\\frac{\\partial z^{(l+1)}_j}{\\partial z^l_j} &= w^{(l+1)} \\sigma'(z^l) \\\\\n",
    "\\therefore \\delta^l &= \\sum_k w^{(l+1)} \\sigma'(z^l) \\delta^{(l+1)}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation for rate of change of cost with respect to biases **\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial C}{\\partial b^l_j} &= \\frac{\\partial C}{\\partial a^l_j} \\frac{\\partial a^l_j}{\\partial z^l_j} \\frac{\\partial z^l_j}{\\partial b^l_j} \\\\\n",
    "\\because \\frac{\\partial z^l_j}{\\partial b^l_j} &= 1 \\\\\n",
    "\\therefore \\frac{\\partial C}{\\partial b^l_j} &= \\frac{\\partial C}{\\partial a^l_j} \\frac{\\partial a^l_j}{\\partial z^l_j} = \\delta^l_j \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation for the rate of change of the cost with respect to Weights**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial C}{\\partial w^l_{jk}} &= a^{(l-1)}_k \\delta^l_j \\\\\n",
    "&= \\frac{\\partial C}{\\partial a^l_j}\\frac{\\partial a^l_j}{\\partial z^l_j}\\frac{\\partial z^l_j}{\\partial w^l_{jk}} \\\\\n",
    "\\because \\frac{\\partial a^l_j}{\\partial z^l_j} &= \\sigma'(z^l_{jk}) \\\\\n",
    "z^l &= w^l a^{(l-1)} + b^l \\\\\n",
    "\\frac{\\partial z^l_j}{\\partial w^l_{jk}} &= a^{(l-1)}_{jk} \\\\\n",
    "\\therefore \\frac{\\partial C}{\\partial w^l_{jk}} &= \\frac{\\partial C}{\\partial a^l_j}\\sigma'(z^l_{jk}) a^{(l-1)}_{jk}\n",
    "\\end{aligned} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford CS231n Notes\n",
    "\n",
    "[Backprop notes](http://cs231n.github.io/optimization-2)\n",
    "\n",
    "[Matrix Calculus](http://cs231n.stanford.edu/handouts/derivatives.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector, Matrix, Tensor Calculus Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $y = Wx$ or $y = xW$:\n",
    "\n",
    "$$ \\frac{\\partial y}{\\partial x} = W $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $Y = XW$ where $X$ is a $d \\times n$ matrix and $W$ is a $d \\times m$ matrix:\n",
    "\n",
    "$$\n",
    "Y = \n",
    " \\begin{pmatrix}\n",
    "  x_{1,1} & x_{1,2} & \\cdots & x_{1,n} \\\\\n",
    "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "  x_{d,1} & x_{d,2} & \\cdots & x_{d,n}\n",
    " \\end{pmatrix}\n",
    " \\begin{pmatrix}\n",
    "  w_{1,1} & w_{1,2} & \\cdots & w_{1,m} \\\\\n",
    "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "  w_{d,1} & w_{d,2} & \\cdots & w_{d,m}\n",
    " \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "In scalar format:\n",
    "\n",
    "$$ y_{i,j} = x_{i,1} w_{1,j} + x_{i,2} w_{2,j} + \\cdots + x_{d,n} w_{d,m} $$\n",
    "\n",
    "In this form, you can see that $i$ specifies **which row** of $X$, $j$ specifies **which column** of $W$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ \\frac{\\partial Y_{i,j}}{\\partial X_{l,k}} &= \n",
    "\\begin{cases}\n",
    "i = l, w_{k,j} \\\\\n",
    "i \\neq l, 0 \\\\\n",
    "\\end{cases} \\\\\n",
    "\\ \\therefore \\frac{\\partial Y_{i,:}}{\\partial X_{i,:}} &= W\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deep Learning Book Notation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of regularization is to move from when a model family included the true data generating process, but also many other possible generating process - the overfitting regime where variance rather than bias dominates the estimation error, to a model that matches the true data generating process.\n",
    "\n",
    "However, most applications of deep learning algos are to domains where the true data generating process is almost certainly **outside the model family**\n",
    "\n",
    "What this means is that, in DL scenarios, we almost always find that the best fitting model is a large model that has been **regularized appropriately**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norm Panelties\n",
    "\n",
    "Bias terms typically require less data than the weights to fit accurately.\n",
    "\n",
    "Typically we choose to use a parameter norm penalty $\\Omega$ that penalizes **only the weights** of the affine transformation at each layer and leaves the biases unregularized.\n",
    "\n",
    "Sometimes it's desirable to use a separate penalty with a different $\\alpha$ coefficient for **each layer** of the network.\n",
    "\n",
    "## $L^2$ Regularization\n",
    "\n",
    "Given objective function:\n",
    "\n",
    "$$ \\hat{J}(w; X, y) = \\frac{\\alpha}{2} w^T w + J(w; X, y) $$\n",
    "\n",
    "Weigtht update is:\n",
    "$$ w \\leftarrow (1- \\epsilon \\alpha) w - \\epsilon \\triangledown_w J(w; X, y) $$\n",
    "\n",
    "We can see that **it shrinks the weight vector by a constant factor on each step**, just before performing the usual gradient descent.\n",
    "\n",
    "$L^2$ is equivalent to MAP Bayesian inference with a Gaussian prior on weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $L^1$ Regularization\n",
    "\n",
    "Given objective function:\n",
    "\n",
    "$$ \\hat{J}(w; X, y) = \\alpha\\| w \\|_1 + J(w; X, y) $$\n",
    "\n",
    "Making assumption that inputs are not correlated (i.e. preprocessed by PCA)\n",
    "\n",
    "$$ w_i = \\text{sign}(w^*_i) \\max \\big\\{ \\mid w^*_i \\mid - \\frac{\\alpha}{H_{i,i}}, 0 \\big\\} $$\n",
    "\n",
    "$L^1$ solution is more *sparse*. The penalty term is equivalent to the log-prior term that maximized by MAP Bayesian inference when the prior is an isotropic Laplace distribution over $w \\in \\mathbb{R}^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norm Panelties as Constrainted Optimization\n",
    "\n",
    "For example, constraint can be $\\Omega(\\theta) < k$.\n",
    "\n",
    "Useful when we have prior knowledge of $k$.\n",
    "\n",
    "Penalties can cause nonconvex optmization procedures to get stuck in local minima corresponding to small $\\theta$. In neural networks, this manifests as neural networks that train with several **dead units**. p231. These are units that do not contribute much to the behaviour of the function learned by the network because weights going into or out of them are all very small.\n",
    "\n",
    "Explicit constraints with reprojection can be useful because they impose some stability on the optimization procedure.\n",
    "\n",
    "Hinton (2012c) recommends using constraints combined with a high learning rate to enable rapid exploration of parameter space while maintaining some stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Robustness\n",
    "\n",
    "Noise applied to the weights can also be interpreted as equivalent (under some assumptions) to a more traditional form of regularization. \n",
    "\n",
    "Error in labels $y$ - treatment is to explicitly model the noise on the labels. [Feels very similar to methods used in Bayesian inference discussed in Statistical Rethinking]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Stop and return parameters that has the lowest validation error, before validation error picks up in a U shape.\n",
    "\n",
    "To reuse validation dataset, two ways:\n",
    "\n",
    "1. initialize the model again and retrain on all the data, but train for the same number of steps as the early stopping procedure. \n",
    "\n",
    "2. Keep parameters from first run and continue training, with all the data. Monitor the average loss function on the validation set and stop until it falls below the value of the training set objective at which the early stopping procedure halted. Avoids the high cost of retraining the model from scratch but not well behaved. e.g. might not reach previous validation set error. \n",
    "\n",
    "Early stopping has the **advantage over weight decay** in that it automatically determines the correct amount of regularization while weight decay requires many training experiments with different values of its hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Sharing\n",
    "\n",
    "Force sets of parameters to be equal. Known as parameter sharing. Used in CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging & Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: p249"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: p251 fill gap here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Effectively an ensemble method. It trains the ensemble consisting of all subnetworks that can be formed by **removing nonoutput** units from an underlying base network.  \n",
    "\n",
    "Some modifications needed for models such as **radial basis function networks**. \n",
    "\n",
    "Dropout aims to approximate **bagging**, but with an exponentially large number of neural networks. It is also not quote the same as bagging. \n",
    "\n",
    "### Training Process\n",
    "\n",
    "1. Starts with minibatch-based learning that makes small steps, such as SGD.\n",
    "2. Each time we load an example into a minibatch, we randomly sample a different binary mask to apply to all the input and hidden units in the network. \n",
    "3. The mask for each unit is sampled independently from all the others. The probability of sampling a mask value of 1 is a hyperparameter fixed before training starts.\n",
    "4. Typically input units is included with a probability of 0.8, and a hidden unit is included with probability of 0.5. \n",
    "5. Then run forward and back-propagation, and the learning update as usual. \n",
    "\n",
    "\n",
    "### Dropout vs Bagging\n",
    "\n",
    "In bagging, all the models are **independent**. In dropout, **models share parameters**. \n",
    "\n",
    "In bagging, each model is trained to convergence on its respective training set. \n",
    "\n",
    "In dropout, typically most models are not explicitly trained at all - usually the model is large enough that it would be infeasible to sample all possible subnetworks within the lifetime of the universe. Instead, **a tiny fraction of the possible subnetworks are each trained for a single step**, and the parameter sharing causes the remaining subnetworks to arrive at good settings of the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Bagging models take arithmetic mean of all predicted distributions. \n",
    "\n",
    "For dropout, each submodel defined by mask vector $\\mu$ defines a probability distribution $p(y \\mid x, \\mu)$. The arithmetic mean over all masks is given by:\n",
    "\n",
    "$$ \\sum_{\\mu} p(\\mu)p(y \\mid x, \\mu) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is **intractable** usually due to exponential number of terms, except when the structure of the model permits some form of simplifications. \n",
    "\n",
    "Instead, we can approximate the inference with sampling, by averaging together the output from many masks. **Even 10-20 masks are often sufficient to obtain good performance.**\n",
    "\n",
    "**A better approach**: change to using the **geometric mean** of the ensemble memebers' predicted distributions. Requirement: **none** of the submodels assign probability 0 to any event, and we renormalize the resulting distribution. \n",
    "\n",
    "Unnormalized probability distribution, $d$ is the number of of units that may be dropped, assuming a uniform distribution over $\\mu$ to simplify:\n",
    "\n",
    "$$ \\hat{p}_{ensemble}(y \\mid x) = \\sqrt[2^d]{\\prod_{\\mu} p(y \\mid x, \\mu} $$\n",
    "\n",
    "To renormalize:\n",
    "\n",
    "$$ p_{ensemble}(y \\mid x) = \\frac{\\hat{p}_{ensemble}(y \\mid x)}{\\sum_{y'} \\hat{p}_{ensemble}(y' \\mid x)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight scaling inference rule**: Hinton (2012c) showed that we can approximate $p_{ensemble}$ by evaluating $p(y \\mid x)$ in one model: the model with all units, but with the weights going out of unit $i$ multiplied by the probability of including unit $i$. Motivation of this modification is **to capture the right expected value of the output from that unit.**\n",
    "\n",
    "Weight scaling rule is **exact** for models that: \n",
    "1. do not have nonlinear hidden units\n",
    "2. regression netowrk with conditionally normal outputs\n",
    "3. deep networks that have hidden layers without nonlinearities. \n",
    "\n",
    "Weight scaling is only **an approximation** for deep models with nonlinearities. \n",
    "\n",
    "Dropout is found to be more effective than other standard computationally inexpensive regularizers, such as weight decay, filter norm constraints, and sparse activity regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Advantages & Attributes\n",
    "\n",
    "* dropout is very computationally cheap. $\\mathcal{O}(n)$ for training, $\\mathcal{O}(n)$ for memory usage.\n",
    "* does not significantly limit the type of model or training procedure that can be used.\n",
    "\n",
    "However, overall cost of the system can be significant. **Dropout reduces effective capacity of a model, to offset this, we must increase the size of the model.**\n",
    "\n",
    "When extremely few labeled training examples are available, dropout is less effective. (book example <5k examples)\n",
    "\n",
    "For linear regression problems, dropout is **equivalent** to $L^2$ weight decay, with a different weight decay coefficient for each input feature. \n",
    "\n",
    "For deep models, dropout is **not equivalent** to weight decay.\n",
    "\n",
    "Mask matrix $\\mu$ can be real valued. Srivastava et al. (2014) showed that multiplying the weights by $\\mu \\sim \\mathcal{N}(1, \\mathit{I})$ can output dropout based on binary masks. Because $\\mathbb{E}[\\mu] = 1$, the standard network automatically implements approximate inference in the ensemble, without needing any weight scaling. \n",
    "\n",
    "Dropout thus regularizes each hidden unit to be not merely a good feature but a feature that is good in many contexts.\n",
    "\n",
    "Dropout can be seen as a form of highly intelligent, adaptive destruction of the information content of the input rather than destruction of the raw values of the input. \n",
    "\n",
    "Another important aspect of dropout is that the noise is **multiplicative**.\n",
    "\n",
    "Batch normalization can instroduces **both additive and multiplicative noise** on the hidden units at training time, sometimes makes dropout unnecessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization, Chapter 8\n",
    "\n",
    "Reference:\n",
    "\n",
    "[An Overview of Gradient Descent Optimization Algorithms](http://sebastianruder.com/optimizing-gradient-descent/index.html?utm_content=buffered5ab&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-Term Dependencies\n",
    "\n",
    "Suppose that a computational graph contains a path that consists of repeatedly multiplying by a matrix $\\mathit{W}$, such as in RNNs, suppose $\\mathit{W}$ has eigen-decomposition $W = V \\text{diag}(\\lambda) V^{-1}$:\n",
    "\n",
    "$$ W^t = \\big(V \\text{diag}(\\lambda) V^{-1}\\big)^t = V \\text{diag}(\\lambda)^t V^{-1} $$\n",
    "\n",
    "Any eigenvalues $\\lambda_i$ that are not near an absolute value of 1 will either explode if they are greater than 1 in magnitude or vanish if they are less than 1 in magnitude.\n",
    "\n",
    "**Vanishing and exploding gradient problem** refers to the fact that gradients through such a graph are also scaled according to $\\text{diag}(\\lambda)^t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping\n",
    "\n",
    "Two ways to do gradient clipping:\n",
    "\n",
    "**Just before the parameter update:**\n",
    "\n",
    "1. clip the parameter gradient from a minibatch element-wise, \n",
    "2. clip the norm $\\| g\\|$ of the gradient:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "if \\| g \\| &\\gt v \\\\\n",
    "g &\\leftarrow \\frac{gv}{\\| g \\|}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The latter has the advantage of guaranteeing that each step is still in the gradient direction, but experiements suggest that both form work similarly.\n",
    "\n",
    "If fact, even taking a **random step** when the gradient magnitude is above a threshold tends to work almost as well.\n",
    "\n",
    "\n",
    "Put another way, traditional stochastic gradient descent uses an unbiased estimate of the gradient, while gradient descent with norm clipping introduces a heuristic bias that we know empirically to be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum SGD\n",
    "\n",
    "SGD parameter update rule, learning rate $\\epsilon$, momentum parameter $\\alpha$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Momentum: } & v \\leftarrow \\alpha v - \\epsilon \\triangledown_{\\theta} \\bigg[ \\frac{1}{m} \\sum_{i=1}^m \\mathit{L}\\big(f(x^{(i)}; \\theta), y^{(i)}\\big)\\bigg] \\\\\n",
    "\\text{Nesterov Momentum: } & v \\leftarrow \\alpha v - \\epsilon \\triangledown_{\\theta} \\bigg[ \\frac{1}{m} \\sum_{i=1}^m \\mathit{L}\\big(f(x^{(i)}; \\theta + \\alpha v), y^{(i)}\\big)\\bigg ]\\\\\n",
    "& \\theta \\leftarrow \\theta + v\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Terminal velocity**: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v &\\leftarrow \\alpha v - \\epsilon g \\\\\n",
    "(1 - \\alpha) v &\\leftarrow - \\epsilon g \\\\\n",
    "v &= \\frac{-\\epsilon g}{1 - \\alpha} \\\\\n",
    "\\text{magnitude of step: }& \\frac{\\epsilon \\| g \\|}{1 - \\alpha}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus it's helpful to think of the momentum hypterparameter in terms of $\\frac{1}{1-\\alpha}$. Common values for $\\alpha$ includes 0.5, 0.9, and 0.99. $\\alpha$ can be adapted over time, but it is less important than shrinking $\\epsilon$ over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parameter Initialization\n",
    "\n",
    "**Breaking Symmetry** between different units: If two hidden units with the same activation function are connected to the same inputs, these units must have different parameters. \n",
    "\n",
    "**Biases** for each unit is typically set to a heuristically chosen constant.\n",
    "\n",
    "**Normalized initialization** p295: sampling each weight in a fully connected layer with $m$ inputs and $n$ outputs from:\n",
    "\n",
    "$$ W_{i,j} \\sim U\\bigg( -\\sqrt{\\frac{6}{m+n}}, \\sqrt{\\frac{6}{m+n}} \\bigg) $$\n",
    "\n",
    "**Sparse initialization** p296: each unit is initialized to have exactly $k$ non-zero weights. However this imposes strong priors on weights that have large Gaussian values. Can cause problems for some units, such as maxout. \n",
    "\n",
    "Treat initial scale of weights as a hyperparameter. Algo in 11.4.2. **Rule of thumb** for choosing the initial scales is to look at the range or standard deviation of activations or gradients on a single minibatch. \n",
    "\n",
    "Setting **biases** to zero is compatible with most weight initialization schemes. A few situations where we may set biases to non-zero values:\n",
    "\n",
    "* If bias is for an output unit, then it's often beneficial to initialize the bias to obtain the right marginal statistics of the output. \n",
    "\n",
    "* Sometimes we may want to choose the bias to avoid causing too much saturation at initialization. \n",
    "\n",
    "* Sometimes a unit controls whether other units are able to participate in a function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithems with Adaptive Learning Rates \n",
    "\n",
    "### AdaGrad, p299\n",
    "\n",
    "Individually adapts the learning rates of all model parameters by scaling them inversely proportional to the square root of the sum of all the historical squared values of the gradient. \n",
    "\n",
    "Given gradient $g$ and parameters $\\theta$:\n",
    "\n",
    "Requires:\n",
    "\n",
    "* global learning rate $\\epsilon$\n",
    "* a small constant $\\delta$ usually $10^{-7}$ to stabilize division by small numbers. \n",
    "\n",
    "Compute gradient: $g \\leftarrow \\frac{1}{m}\\Delta_\\theta \\sum_i \\mathit{L}\\big(f(x^{(i)}; \\theta), y^{(i)} \\big)$\n",
    "\n",
    "Accumulate squared gradient $r \\leftarrow r + g \\odot g$\n",
    "\n",
    "Compute gradient update: $\\Delta\\theta \\leftarrow -\\frac{\\epsilon}{\\delta + \\sqrt{r}} \\odot g$\n",
    "\n",
    "Apply update: $\\theta \\leftarrow \\theta + \\Delta\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp\n",
    "\n",
    "One of the most effective and practical optimization algorithm for deep neural networks. \n",
    "\n",
    "Constrast to AdaGrad, it uses an exponentially decaying average to discard history from the extreme past.\n",
    "\n",
    "Requires:\n",
    "\n",
    "* decay rate, $\\rho$\n",
    "* a small constant $\\delta$ usually $10^{-6}$ to stabilize division by small numbers\n",
    "\n",
    "Algo:\n",
    "\n",
    "Accumulate squared gradient $r \\leftarrow \\rho r + (1-\\rho) g \\odot g$\n",
    "\n",
    "Compute gradient update: $\\Delta\\theta \\leftarrow -\\frac{\\epsilon}{\\delta + \\sqrt{r}} \\odot g$\n",
    "\n",
    "Apply update: $\\theta \\leftarrow \\theta + \\Delta\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp with Nesterov Momentum\n",
    "\n",
    "Additionally Requires:\n",
    "\n",
    "* momentum coefficient $\\alpha$\n",
    "* initial velocity $v$:\n",
    "\n",
    "Compute interim update: $\\widetilde{\\theta} \\leftarrow \\theta + \\alpha v$\n",
    "\n",
    "Compute gradient: $g \\leftarrow \\frac{1}{m}\\Delta_\\theta \\sum_i \\mathit{L}\\big(f(x^{(i)}; \\widetilde{\\theta}), y^{(i)} \\big)$\n",
    "\n",
    "Accumulate squared gradient $r \\leftarrow \\rho r + (1-\\rho) g \\odot g$\n",
    "\n",
    "Compute velocity update: $v \\leftarrow \\alpha v - \\frac{\\epsilon}{\\sqrt{r}} \\odot g$\n",
    "\n",
    "Rest is the same as RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam (Adaptive Momentum)\n",
    "\n",
    "Requires:\n",
    "\n",
    "A small constant $\\delta$ usually $10^{-8}$ to stabilize division by small numbers,\n",
    "\n",
    "Exponential decay rates for momentum estimates, $\\rho_1$ and $\\rho_2$ in $[0, 1)$\n",
    "\n",
    "Algo:\n",
    "\n",
    "Update biases first momentum estimate: $s \\leftarrow \\rho_1 s + (1-\\rho_1)g$\n",
    "\n",
    "Update biases second momentum estimate: $r \\leftarrow \\rho_2 r + (1-\\rho_2)g \\odot g$\n",
    "\n",
    "Correct bias in first momentum: $\\hat{s} = \\frac{s}{1 - \\rho_1^t}$\n",
    "\n",
    "Correct bias in second momentum: $\\hat{r} = \\frac{r}{1 - \\rho_2^t}$\n",
    "\n",
    "Compute uipdate: $\\Delta_{\\theta} = -\\epsilon \\frac{\\hat{s}}{\\sqrt{\\hat{r}} + \\delta} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='batchnorm'></a>\n",
    "## Batch Normalization p309"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Problem: gradient tells us how to update each parameter, **under the assumption that the other layers do not change**. In practice, we update all the layers simultaneously. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "\n",
    "* understand the example in book\n",
    "* understand detailed numerical example of how BN works and how back-prop works in this context\n",
    "    * read [this](https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html) and [this](http://cthorey.github.io./backpropagation/)\n",
    "    * [BN in Tensorflow](http://ruishu.io/2016/12/27/batchnorm/)\n",
    "    * [Stack Overflow Answer with pointers to Keras](https://stats.stackexchange.com/questions/215458/what-is-an-explanation-of-the-example-of-why-batch-normalization-has-to-be-done)\n",
    "    * [R2RT Example in TensorFlow](https://r2rt.com/implementing-batch-normalization-in-tensorflow.html)\n",
    "    * [cs231n 2016 Lectures by Andrej Karpathy](https://www.youtube.com/watch?v=gYpoJMlgyXA&index=5&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch normalization (refered to as **BN** below) can be applied to any input or hidden layer in a network.\n",
    "\n",
    "Define:\n",
    "\n",
    "* $\\mathbf{H}$: a minibatch of activations of the layer to normalize, arranged as a design matrix, with the activations for each example appearing in a **row** of the matrix.\n",
    "\n",
    "To normalize:\n",
    "\n",
    "$$ H' = \\frac{H - \\mu}{\\sigma} $$\n",
    "\n",
    "where:\n",
    "\n",
    "* $\\mu$ is a vector containing the mean of each unit,\n",
    "* $\\sigma$ is a vector containing the standard deviation of each unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maths Details for Batch Norm Backprop\n",
    "\n",
    "This [post](http://cthorey.github.io./backpropagation/) showed some of the maths work behinding batch norm. \n",
    "\n",
    "[Here](./BatchNorm_Maths.ipynb) I produce my work following this article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### At Training time:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu &= \\frac{1}{m}\\sum_{i} \\mathbf{H}_{i,:} \\\\\n",
    "\\sigma &= \\sqrt{\\delta + \\frac{1}{m}\\sum_{i}(\\mathbf{H} - \\mu)^2_i}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $\\delta$ is a small positive value such as $10^{-8}$, imposed to avoid encountering the undefined gradient of $\\sqrt{z}$ at $z = 0$.\n",
    "\n",
    "**Crucially, we back-prop through these operations for computing the mean and the standard deviation**, and for applying them to normalize $\\mathbf{H}$. \n",
    "\n",
    "This means that the gradient will never propose an operation that acts simply to increase the standard deviation or mean of $h_i$.\n",
    "\n",
    "Previous methods:\n",
    "\n",
    "* adding penalities to the cost function to encourage units to have normalized activation statistics,\n",
    "    * **drawback**: results in imperfect normalization \n",
    "* intervening to renormalize unit statistics after each gradient descent step. \n",
    "    * **drawback**: results in significant waste of time, as the learning algo repeatedly proposed changing the mean and variance, which the normalization step repeatedly undid this change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At Test time:\n",
    "\n",
    "$\\mu$ and $\\sigma$ may be replaced by running averages that were collected during training time. \n",
    "\n",
    "    * enables the model to be evaluated on a single example (vs minibatch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BN** acts to standardize only the mean and variance of each unit in order to stablize learning, but it allows the relationship betwen units and the nonlinear statistics of a single unit to change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is commont to replace the batch of hidden unit activiations $\\mathbf{H}$ with $\\gamma\\mathbf{H}' + \\beta$, rather than simply the normalized $\\mathbf{H}'$. It looks confusing as BN centers the activations mean to 0, but this step introduces nonzero mean. However, this method is significantly easier to learn with gradient descent - the mean is solely depended on $\\beta$, not a complicated interaction between the parameters in the layers below $\\mathbf{H}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most network layers takes the form of $\\phi\\big(\\mathbf{XW} + b\\big)$, question is whether to normalize $\\mathbf{X}$ or $\\mathbf{XW} + b$.\n",
    "\n",
    "Ioffe and Szegedy (2015) recommends using normalized $\\mathbf{XW}$ (as $b$ is replaced by $\\beta$ of the BN reparametrization).\n",
    "\n",
    "Other attributes:\n",
    "\n",
    "* BN enables **higher** learning rates, trains faster\n",
    "* BN **regularizes** the model.\n",
    "* Imporoves gradient flow through the network\n",
    "* Reduces the strong dependence on initilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='batchnorm_paper'></a>\n",
    "## Batch Norm Paper\n",
    "\n",
    "[paper](https://arxiv.org/abs/1502.03167)\n",
    "\n",
    "[cs231 video](https://www.youtube.com/watch?v=gYpoJMlgyXA&index=5&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC)\n",
    "\n",
    "Define **Internal Covariate Shift** as the change in the distribution of network activations due to the change in network parameters during training. \n",
    "\n",
    "**Notation** \n",
    "\n",
    "A layer with $d$-dimensional input $x=(x^{(1)}, \\cdots, x^{(d)})$, normalize each dimension. \n",
    "\n",
    "### Training\n",
    "\n",
    "For each minibatch $\\mathcal{B}$ of size $m$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu_{\\mathcal{B}} &= \\frac{1}{m} \\sum_{i=1}^{m} x_i &\\text{minibatch mean} \\\\\n",
    "\\sigma_{\\mathcal{B}}^2 &= \\frac{1}{m} \\sum_{i=1}^{m} (x_i - \\mu_{\\mathcal{B}})^2 &\\text{minibatch variance} \\\\\n",
    "\\hat{x} &= \\frac{x_i - \\mu_{\\mathcal{B}}}{\\sigma_{\\mathcal{B}}^2 + \\epsilon} &\\text{normalize} \\\\\n",
    "y_i &= \\gamma \\hat{x}_i + \\beta = BN_{\\gamma,\\beta}(x_i) &\\text{scale & shift}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Test / Inference\n",
    "\n",
    "At test time, normalization is done using stats from the **training population**, rather than minibatch:\n",
    "\n",
    "$$ \\hat{x} = \\frac{x - \\mathbb{E}[x]}{\\sqrt{Var[x] + \\epsilon}} $$\n",
    "\n",
    "where the expectation is over **training minibatches** of size $m$ and $\\sigma_{\\mathcal{B}}^2$ are their sample variances.\n",
    "\n",
    "For clarity:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[x] &= \\mathbb{E}_{\\mathcal{B}} [\\mu_{\\mathcal{B}}] \\\\\n",
    "Var[x] &= \\frac{m}{m-1} \\times \\mathbb{E}_{\\mathcal{B}} [\\sigma_{\\mathcal{B}}^2] \\\\\n",
    "y &= \\frac{\\gamma}{\\sqrt{Var[x] + \\epsilon}} \\times x + \\bigg(\\beta -  \\frac{\\gamma \\mathbb{E}[x]}{\\sqrt{Var[x] + \\epsilon}}\\bigg)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Using **moving averages** instead, we can track the accuracy of a model as it trains.\n",
    "\n",
    "Andrej Karpathy also mentioned in his lecture that you can compute this over the entire data set also. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate Descent, p312\n",
    "\n",
    "Minimize $f(x)$ with respect to a single variable $x_i$, then minimize it with respect to another variable $x_j$, and so on. Repeatly cycling through all the variables, we are guaranteed to arrive at a **local** minimum. \n",
    "\n",
    "**Block coordinate descent** refers to minimizing with respect to a subset of the variables simultaneously.\n",
    "\n",
    "Coordinate descent is **not** a good strategy when the value of one variable strongly influences the optimal value of another variable. E.g. $f(x) = (x_1 - x_2)^2 + \\alpha (x^2_1 + x^2_2), \\alpha \\gt 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polyak Averaging, p313\n",
    "\n",
    "Polyak averaging consists of averaging several points in the trajectory through parameter space visited by an optimization algorithm. \n",
    "\n",
    "If $t$ iterations of gradient descent vist points $\\theta^{(1)}, \\cdots, \\theta^{(t)}$, then the output of the Polyak averaging altorithm is $\\hat{\\theta}^{(t)} = \\frac{1}{t}\\sum_i \\theta^{(i)}$\n",
    "\n",
    "Polyak averaging for convex optimization has strong guarantee for convergence. For neural networks, it's more heuristic, but works well in practice. \n",
    "\n",
    "In nonconvex problems, it is typical to use an exponentially decaying running average:\n",
    "\n",
    "$$\\hat{\\theta}^{(t)} = \\alpha \\hat{\\theta}^{(t-1)} + (1-\\alpha)\\theta^{(t)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Methodology\n",
    "\n",
    "Based on DL, material based on [Andrew Ng](http://cs229.stanford.edu/materials/ML-advice.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "\n",
    "**Precision** as $p$: fraction of detections reported by the model that were correct, (correct predictions / all predictions).\n",
    "\n",
    "**Recal** as $r$: fraction of the true events that were detected (% of true positives detected).\n",
    "\n",
    "**F1-Score**\n",
    "\n",
    "$$ F = \\frac{2pr}{p + r} $$\n",
    "\n",
    "**AUC**: Area under the Precision-Recall curve.\n",
    "\n",
    "**Coverage**: is the fraction of examples for which the machine learning system is able to produce a response. It is possible to trade coverage for accuracy (the error rate of a system). \n",
    "\n",
    "**Define which performance metrics to improve ahead of time, then concentrate on improve it.** Need to define goal post first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Establish an end-to-end system ASAP\n",
    "\n",
    "Choose model based on general category: feedforward network, convolutional network if input has known topological structure. Use ReLU/Leaky ReLU.\n",
    "\n",
    "If input or output is a sequence, use gated RNN, such as LSTM or GRU.\n",
    "\n",
    "Use **SGD with momentum with a decaying learning rate**. Or **Adam**. If optimization is problematic, use **batch normalization** quickly.\n",
    "\n",
    "Use **early stopping**. **Dropout** to regularize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather More Data or Not\n",
    "\n",
    "If **training error** is poor, no need to collect data, **increase the size of the model** by adding more layers or more hidden units to each layer. Or **tune the model such as hyperparameters**.\n",
    "\n",
    "If using large model and carefully tuned hyperparameters, training error is still high, then there may be **data quality** issues. Collect more data, clean the data, start again.\n",
    "\n",
    "If training error is acceptable but **test error** is not, **collect more data**.\n",
    "\n",
    "Plot curve showing relationship between **training data size** and **generalization error rate**. By extrapolating, one can predict how much additional training data would need to be gathered to reach a performance goals.\n",
    "\n",
    "Data size should be viewed in **log scale**, i.e. double the size of data between experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Hyperparameter Tuning\n",
    "\n",
    "Primary goal: **adjust the effective capacity of the model to match the complexity of the task**.\n",
    "\n",
    "Effective capacity constrained by 3 factors:\n",
    "\n",
    "1. the representational capacity of the model.\n",
    "2. ability of the learning algothrim to successfully minimize the cost function used to train the model.\n",
    "3. the degree to which the cost function and the training procedure regularize the model.\n",
    "\n",
    "Generalization error is typically **U-shaped** when plotted against one of the hyperparameters.\n",
    "\n",
    "Not every hyperparameter will be able to explore the entire U-shaped curve.\n",
    "\n",
    "The effective capacity is highest when the **learning rate** is **correct** for the optimization problem. Learning rate has a U-shaped curve for training error.\n",
    "\n",
    "Tuning parameters other than the learning rate reuiqres monitoring both training and test error to diagnose whether your model is overfitting or underfitting.\n",
    "\n",
    "Test Error = Training Error + Gap between Training and Test Error\n",
    "\n",
    "Neural networks typically perform best when the **training error is very low (thus when capacity is high)**, so test error is primiarly driven by the gap between the two errors. **Goal** is to reduce this gapp without increasing training error faster than the gap decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Hyperparameter Tuning\n",
    "\n",
    "**Grid search** typically involves picking values approximately on a log scale. \n",
    "\n",
    "**Random search** typically reduces validation error much faster than grid search, in terms of the number of trials run by each method. Often this is **repeated many times** to refine the search based on the results of the first run.\n",
    "\n",
    "See Ian Goodfellow's tip on this [here](https://www.quora.com/Whats-Ian-Goodfellows-favourite-approach-to-hyperparameter-optimization):\n",
    "\n",
    "\"Random search-run 25 jobs in parallel with random hyperparameters, choose the best 23 jobs, tighten the random distributions to spend more time near those best jobs, and run another 25.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Based Hyperparameter Optimization\n",
    "\n",
    "No conclusive results yet for Bayesian hyperparameter optimization yet.\n",
    "\n",
    "One drawback common to most hyperparameter optimization algos is that they require for a training experiment to run to completion before they are able to extract any information from the experiment. Thus much less efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Strategy, p424\n",
    "\n",
    "Two ways:\n",
    "\n",
    "* Design a case that is so simple that the correct behaviour can be predicted.\n",
    "* design a test the exercises one part of the neural net implementation in isolation.\n",
    "\n",
    "Important tests:\n",
    "\n",
    "* visualize the model in action\n",
    "* visualize the worst mistakes\n",
    "* Reason about software using training and test error (overfitting symptoms can be caused by model not saved right, test data not processed in the same way as training data, etc)\n",
    "* Fit a tiny dataset\n",
    "* Compare backprop derivatives to numerical derivatives: compare automatic differentiation to **finite differences**\n",
    "* Monitor histograms of activations and gradient. would like the magnitude of parameter updates over a minibatch to be around **1% of the magnitude of the parameter**, not 50% or 0.0001%.\n",
    "    * sparse data results in some parameters to be updated very rarely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
