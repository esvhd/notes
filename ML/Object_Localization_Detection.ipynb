{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Andrew Ng\n",
    "\n",
    "## Classification with Localization\n",
    "\n",
    "Conv net with softmax output and bounding box $(b_x, b_y, b_h, b_w)$. Training set contains class labels and bounding boxes.\n",
    "\n",
    "Assuming 1 object in an image, label $y = (p_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3)$ where:\n",
    "\n",
    "* $p_c$ is the probability that there is an object of interest\n",
    "* $c_1, c_2, c_3$ are class labels.\n",
    "* $(b_x, b_y, b_h, b_w)$ are coordinates in the image.\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "Typically: \n",
    "\n",
    "**Logistic regression loss** for $p_c$,\n",
    "\n",
    "**mean square error** for bounding box parameters\n",
    "\n",
    "** softmax loss** for class labels $c_1, c_2, c_3$.\n",
    "\n",
    "Example:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}(\\hat{y}, y) &= \\begin{cases}\n",
    "\\sum_{i=1} \\big(\\hat{y}_i - y_i \\big)^2 & if y_1 == 1 \\\\\n",
    "\\big(\\hat{y}_1 - y_1 \\big)^2 & if y_1 == 0\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The case where there is no object, the terms other than the first item in the label are not relevant.\n",
    "\n",
    "Coordinate landmarks can also be used to classify the pose of a person in an image, provided that the cordinates of the body are labelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection\n",
    "\n",
    "### Sliding window detection\n",
    "\n",
    "Use a varity of window sizes to slide across an image and classify the windowed image for possible class.\n",
    "\n",
    "**Disadvantage**: computational cost due to large number of windows. May miss objects due to stride size.\n",
    "\n",
    "### CNN Implementation of Sliding Windows\n",
    "\n",
    "Typically you have input -> CONV -> Max Pool -> FC -> FC -> Softmax\n",
    "\n",
    "However, you can replace the FC layers with CONV layers with # of filters same as the size of the width of FC layers, ie. if FC has 400 neurons, we can replace it with filters matching the size of previous layer, but 400 of them. \n",
    "\n",
    "Then it can be followed by 1x1x400 CONV layers, then to a 1x1x4 CONV layer if there are 4 classes for the softmax layer. Max pool size is (2, 2).\n",
    "\n",
    "Creating the windows results in lots of duplicated computation. Therefore for instead of using 14x14x3 images and 1x1x4 softmax in the end, you can instead use 16x16x3 images, with the same filters, but get a 2x2x4 output for softmax in the end.\n",
    "\n",
    "Each order of the 2x2x4 output represent a subset of the 16x16x3 imanges, echo of wich is 14x14x3. Therefore 4 images can be done in one pass.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## YOYL (You Only Look Once) 2015\n",
    "\n",
    "Split an image into grids. For each grid cell, the label is $y = (p_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3)$.\n",
    "\n",
    "For example an impage is split into 3x3 grids (in practice typically use 19x19 grids). Find the mid point of each object in each cell.\n",
    "\n",
    "Input 100x100x3 -> CONV -> MAX POOL -> ... -> Output 3x3x8.\n",
    "\n",
    "$(b_x, b_y, b_h, b_w)$ are expressed relative to the size of the grid cell. $(b_x, b_y)$ they have to be [0, 1]. $(b_h, b_w)$ could be > 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Intersection Over Union (IOU)\n",
    "\n",
    "Used to evaluate objection. Computers: **IOU = size of intersection / size of union**. \n",
    "\n",
    "If IOU >= 0.5, then correct. Or 0.6, 0.7, etc.\n",
    "\n",
    "It measure the overlap of two boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Max Suppression\n",
    "\n",
    "Ensure your algo detects an object only once. \n",
    "\n",
    "Multiple cells in a grid of a picture may have high $p_c$, probability of detection. \n",
    "\n",
    "Non-Max suppression algo:\n",
    "\n",
    "* For a cluster of boxes with high $p_c$, choose the one with the highest $p_c$, \n",
    "* Checks all other boxes with high IOU, suppress them. \n",
    "\n",
    "Example, for a 19x19 grid, for 1 object:\n",
    "\n",
    "\n",
    "1. discard all boses with $p_c \\leq 0.6$ \n",
    "2. while there are remaining bounding boxes:\n",
    "    * pick the box with the largest $p_c$, output that as a prediction\n",
    "    * discard any remaining box with IOU >= 0.5 with the box output in the prevoius step (this drops boxes that are potentially flagging the same object).\n",
    "    \n",
    "For multiple objects, repeat for each object class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Boxes\n",
    "\n",
    "For dealing with **overlapping objects**, those with the **same midpoint**. \n",
    "\n",
    "For the case of 2 objects: change the encoding from $y = (p_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3)$ to:\n",
    "\n",
    "$$y = (p_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3, p_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3)$$\n",
    "\n",
    "Use the first group for anchor box 1, and the second group for anchor box 2. \n",
    "\n",
    "Each object in training image is assigned to grid cell that contains object's midpoint and anchor box for the grid cell with highest IOU.\n",
    "\n",
    "## YOLO\n",
    "\n",
    "To detect 3 classes: pedestrian/car/motocycle, **dimension** of $y$ that has 2 anchor boxes: 3x3x2x8 or 3x3x16, (output of your CNN).\n",
    "\n",
    "Then run non-max suppression, for each object class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Proposal\n",
    "\n",
    "R-CNN (2013). Run **segmentation algorithm** to find regions to run CNN classifier on. Reduces the no. of regions to run through CNN.\n",
    "\n",
    "Fast R-CNN speeds up quite a bit. However, proposal algo still slow. \n",
    "\n",
    "Faster R-CNN runs faster, but still slower than YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
