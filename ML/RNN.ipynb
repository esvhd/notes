{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Book\n",
    "\n",
    "# Chapter 10 Sequence Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN operates on a **sequence** that contains **vectors** $x^{(t)}$ with the time step index $t$ ranging from 1 to $\\tau$. \n",
    "\n",
    "In practice, RNNs usually operate on minibatches of such sequences, with a different length $\\tau$ for each member of the minibatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "\n",
    "check out this [video](https://www.youtube.com/watch?v=Ukgii7Yd_cU) from Intel Nervana.\n",
    "\n",
    "Hinton's course on [Coursera](https://www.coursera.org/learn/neural-networks#syllabus) on RNNs. \n",
    "\n",
    "FastAI's course on [RNN](http://course.fast.ai/lessons/lesson6.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing or Exploding Gradients\n",
    "\n",
    "Biggest eigenvalue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RNN Computation\n",
    "\n",
    "Video from Stanford's [cs224d](https://www.youtube.com/watch?v=MeIrQCZvlkE&t=3990s) on RNN. And [here](https://www.youtube.com/watch?v=Keqep_PKrY8) for the 2017 version.\n",
    "\n",
    "My notes for Stanford's [cs231n](./cs231n.ipynb#rnn).\n",
    "\n",
    "Given list of word vectors: $x_1, x_2, \\cdots, x_t, \\cdots, x_T$\n",
    "\n",
    "At single time step: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "h_t &= \\sigma\\bigg( W_{hh} h_{t-1} + W_{hx} x_t \\bigg) \\\\\n",
    "\\hat{y}_t &= softmax\\bigg(W_{S} h_t\\bigg) \\\\\n",
    "\\hat{P}(x_{t+1} = v_j \\mid x_t, \\cdots, x_1) &= \\hat{y}_{t,j} \\\\\n",
    "W_{hh} &\\in \\mathbb{R}^{D_h \\times D_h} \\\\\n",
    "W_{hx} &\\in \\mathbb{R}^{D_h \\times d} \\\\\n",
    "W_{S} &\\in \\mathbb{R}^{V \\times D_h}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For computation of $f(z_1 + z_2) = f(W_1 x_1 + W_2 x_2)$, form the following matricies:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W' &= concat(W_1, W_2, axis=1) \\\\\n",
    "X' &= concat(x_1, x_2, axis=0) \\\\\n",
    "f(W_1 x_1 + W_2 x_2) &= f(W'X')\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "If $W_1$ is $N \\times N$, $W'$ is $N \\times 2N$, i.e. concat **horizontally**.\n",
    "\n",
    "If $x_1$ is $N \\times 1$, $X'$ is $2N \\times 1$, i.e. concat **vertically**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Forcing, p372\n",
    "\n",
    "A RNN whose only recurrence is the feedback connection from the output of the hidden layer, not the hidde layer itself, is **less powerful** than those which have direct connection from hidden layer $h^{(t-1)}$ to $h^{(t)}$. p370.\n",
    "\n",
    "The advantage of eliminating hidden-to-hidden recurrence is that, for any loss function based on comparing the prediction at time $t$ to the training target at time $t$, all the time steps are decoupled. Tranining can thus be parallelized, with gradient for each step t computed in isolation.\n",
    "\n",
    "Teacher forcing is a procedure that emerges from the maximum likelihood criterion, in which during training the model receives the ground truth output $y^{(t)}$ as input at time $t+1$, instead of the output from the previous step, thus parallelizing training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPTT\n",
    "\n",
    "The backprop algorithm applied to the unrolled graph with $\\mathbb{O}(\\tau)$ cost is called **back-propagation through time (BPTT)**. As soon as the hidden units become a function of earlier time steps, the BPTT algorithm is necessary.\n",
    "\n",
    "Example is based on the RNN architecture given in figure 10.3 on page 369. This network is described as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "a^{(t)} &= b + W h^{(t-1)} + U x^{(t)}, &(10.8)\\\\\n",
    "h^{(t)} &= \\tanh\\big(a^{(t)}\\big), &(10.9)\\\\\n",
    "o^{(t)} &= c + V h^{(t)}, &(10.10)\\\\\n",
    "\\hat{y}^{(t)} &= \\text{softmax}\\big( o^{(t)} \\big), &(10.11)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "* $x$ are input sequences\n",
    "* $o$ outputs of corresponding $x$\n",
    "* $y$ training target for corresponding $x$\n",
    "* $U$ weight matrix for input-to-hidden connections\n",
    "* $W$ weight matrix for hidden-to-hidden connections\n",
    "* $V$ weight matrix for hidden-to-output connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, **derivate of `softmax(x)`**, see this [post](http://peterroelants.github.io/posts/neural_network_implementation_intermezzo02/), using the quotient rule:\n",
    "\n",
    "$$ \\big(\\frac{f}{g}\\big)' = \\frac{f'g - fg'}{g^2} $$\n",
    "\n",
    "Let $f = e^x$, $g = \\sum_i e^{x_i}$, $y = \\text{softmax}(x)$ and $y_i$ be the result for $x_i$, $x \\in R^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $i = j$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial y_i}{\\partial x_i} &= \\frac{e^{x_i} g - e^{x_i} (0 + \\cdots + e^{x_i} + 0 + \\cdots + 0)}{g^2} \\\\\n",
    "&= \\frac{e^{x_i} g - e^{x_i} e^{x_i}}{g^2} \\\\\n",
    "&= \\frac{e^{x_i} (g - e^{x_i})}{g^2} \\\\\n",
    "&= \\frac{e^{x_i}}{g} \\times \\frac{g - e^{x_i}}{g}\\\\\n",
    "&= y_i \\times (1 - \\frac{e^{x_i}}{g}) \\\\\n",
    "&= y_i \\times (1 - y_i)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $i \\neq j$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial y_i}{\\partial x_j} &= \\frac{0 \\times g - e^{x_i} e^{x_j}}{g^2} \\\\\n",
    "&= -\\frac{e^{x_i}}{g} \\frac{e^{x_j}}{g} \\\\\n",
    "&= - y_i y_j\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to BPTT, we start from the node immediately preceding the final loss:\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial L^{t}} = 1 $$\n",
    "\n",
    "Then we have\n",
    "\n",
    "$$(\\triangledown_{o^{t}}L)_i = \\frac{\\partial L}{\\partial o^{t}_i} = \\frac{\\partial L}{\\partial L^{t}} \\frac{\\partial L^{t}}{\\partial o^{t}_i} = \\hat{y}^{(t)}_i - 1_{i,y^{(t)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM - Long Short-Term Memory\n",
    "\n",
    "Chris Olah's [post](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "**Nando De Freitas**'s [lecture](https://www.youtube.com/watch?v=56TYLaQN4N8&list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu&index=14): parameter updates act like writing to memory. We need a way to decide when to read, write and erase the memory. Hence we arrive at LSTM, which learns from the data when to read, write and erase.\n",
    "\n",
    "Components of LSTM cell:\n",
    "\n",
    "## Forget gate \n",
    "\n",
    "Decides what info we are going to throw away from the cell state. \n",
    "\n",
    "* Inputs: $h_{t-1}$ from the same layer, input $x_t$ or $h_t$ from the previous layer.\n",
    "* Output: a number between 0 and 1 for each number in the cell state $C_{t-1}$. 1 is keep everything, 0 is forget everything.\n",
    "\n",
    "$$ f_t = \\sigma\\big( W_f \\times [ h_{t-1}, x_t] + b_f\\big) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Gate, tanh layer\n",
    "\n",
    "Next step is to decide what new info we are going to store in the cell state, done in two parts. \n",
    "* Input gate\n",
    "* tanh layer\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "i_t &= \\sigma\\big( W_i \\times [h_{t-1}, x_t] + b_i \\big) \\\\\n",
    "\\tilde{C}_t &= \\tanh \\big( W_C \\times [h_{t-1}, x_t] + b_C \\big)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5535d797b8>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA9npAfaKyogAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5535e23860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-3, 3, num=100)\n",
    "y = np.tanh(x)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell State\n",
    "\n",
    "Next step is to update the **old** cell state, $C_{t-1}$, into the **new** cell state $C_t$. Inputs are the outputs from **forget gate**, **input gate**, and **tanh layer**. $\\odot$ represents element-wise multiplication.\n",
    "\n",
    "$$ C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ouput \n",
    "\n",
    "Work out the output of the cell, using sigmoid to decide which parts of the cell state we are going to output. \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "o_t &= \\sigma \\big( W_o \\times [h_{t-1}, x_t] + b_o \\big) \\\\\n",
    "h_t &= o_t \\odot \\tanh(C_t)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula Summary\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "i_t &= \\sigma\\big( W_i \\times [h_{t-1}, x_t] + b_i \\big) \\\\\n",
    "f_t &= \\sigma\\big( W_f \\times [ h_{t-1}, x_t] + b_f\\big) \\\\\n",
    "o_t &= \\sigma \\big( W_o \\times [h_{t-1}, x_t] + b_o \\big) \\\\\n",
    "g = \\tilde{C}_t &= \\tanh \\big( W_C \\times [h_{t-1}, x_t] + b_C \\big) \\\\\n",
    "C_t &= f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t \\\\\n",
    "h_t &= o_t \\odot \\tanh(C_t)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers\n",
    "\n",
    "Parameters in the same layer are shared in all recurrent steps. Different layers will have different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Variants\n",
    "\n",
    "## Gers & Schmidhuber (2000)\n",
    "\n",
    " Add **peephole connections**, allowing the gates to look at the cell state. Modifications:\n",
    " \n",
    "$$\n",
    "\\begin{aligned}\n",
    "f_t &= \\sigma \\big( W_f \\times [C_{t-1}, h_{t-1}, x_t] + b_f \\big) \\\\\n",
    "i_t &= \\sigma \\big( W_i \\times [C_{t-1}, h_{t-1}, x_t] + b_i \\big) \\\\\n",
    "o_t &= \\sigma \\big( W_o \\times [C_{t}, h_{t-1}, x_t] + b_o \\big) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## Coupled Forget and Input Gates\n",
    "\n",
    "Make **forget** and **input** (cell update) gates make decision together.\n",
    "\n",
    "$$ C_t = f_t \\odot C_{t-1} + (1-f_t) \\odot \\tilde{C}_t $$\n",
    "\n",
    "## GRU (Gated Recurrent Unit)\n",
    "\n",
    "Combines **forget** and **input** gates into a single **update** gate, merges **cell state** and **hidden state**, plus othe changes. \n",
    "\n",
    "* Input: $h_{t-1}$, $x_t$\n",
    "* Output: $h_t$\n",
    "\n",
    "It is simpler than the standard LSTM, increasingly popular. \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_t &= \\sigma \\big( W_z \\times [h_{t-1}, x_t] \\big) \\\\\n",
    "r_t &= \\sigma \\big( W_r \\times [h_{t-1}, x_t] \\big) \\\\\n",
    "\\tilde{h}_t &= \\tanh \\big( W \\times [r_t \\times h_{t-1}, x_t] \\big) \\\\\n",
    "h_t &= (1 - z_t) \\times h_{t-1} + z_t \\times \\tilde{h}_t\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "Next big step is **attention**. This is as of 2015. See Olah's other [post](https://distill.pub/2016/augmented-rnns/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on RNN, Andrea Karpathy's [post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
