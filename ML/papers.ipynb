{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Papers\n",
    "\n",
    "[Highway Networks](#highway)\n",
    "\n",
    "[DenseNet](#densenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='highway'></a>\n",
    "## Highway Networks\n",
    "\n",
    "[Summary Paper](https://arxiv.org/abs/1505.00387)\n",
    "\n",
    "[Full Paper](https://arxiv.org/abs/1507.06228)\n",
    "\n",
    "\n",
    "Highway networks enables the optimization of the networks with virtually arbitary depth. This is accomplished through the use of a **learned gating machanism** for regulating information flow wihch is inspired by LSTM.\n",
    "\n",
    "The paper shows that the optimization of highway network is virtually independent of depth. Used to train a 900-layer network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plain feedforward network of $L$ layers with $H$ as a non-linear transform function, ignoring layer index:\n",
    "\n",
    "$$ y = H(x, W_H) $$\n",
    "\n",
    "For a highway network, the paper adds two non-linear transform: \n",
    "* Tranform gate, $T(x W_T)$\n",
    "* Carry gate, $C(x, W_C)$\n",
    "\n",
    "$$ y = H(x, W_H) \\cdot T(x, W_T) + x \\cdot C(x, W_C) $$\n",
    "\n",
    "The paper sets $C = 1 - T$\n",
    "\n",
    "The **dimensionality** of $x$, $y$, $H(x, W_H)$ and $T(x, W_T)$ must be the same for the equation above to hold.\n",
    "\n",
    "If size of the representation needs to be changed, two ways:\n",
    "\n",
    "1. replace $x$ with $\\tilde{x}$ obtained by suitably sub-sampling or zero-padding $x$\n",
    "2. Use a plain layer without highway to change dimensionality and then continue with stacking highway layers. This is what the paper used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform gate** is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "T(x) &= \\sigma(W_T^T x + b_T) \\\\\n",
    "\\sigma(x) &= \\frac{1}{1 + e^{-x}}, x \\in \\mathbb{R}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$b_T$ can be initialized with a negative number (e.g. -1, -3, etc) such that the network is biased initially towards **carry** behaviour. The paper found that during training, $b_T$ actually got further negative, this behavour suggests that the strong negative biases at low depths are not used to shut down the gates, but to make them more selective. \n",
    "\n",
    "$W_H$ can be initialized with various zero mean distributins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "<a id='densenet'></a>\n",
    "## Densely Connected Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
