{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Papers\n",
    "\n",
    "[Weight Normalization](#weight_norm)\n",
    "\n",
    "[Highway Networks](#highway)\n",
    "\n",
    "[DenseNet](#densenet)\n",
    "\n",
    "[Bootstrap](#bootstrap)\n",
    "\n",
    "[LSTM/RHN on Natural Language Modeling](#1707.05589)\n",
    "\n",
    "[Clustering Financial Time Series](#clustering_ts)\n",
    "\n",
    "[Temporal Convolutional Networks](#tcn)\n",
    "\n",
    "[Layer Normalization](#layer_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='weight_norm'></a>\n",
    "## Weight Normalization\n",
    "\n",
    "[paper](https://arxiv.org/abs/1602.07868)\n",
    "\n",
    "Speeds up SGD convergence by regularizing the weight norm. For a given network:\n",
    "\n",
    "$$ y = \\phi(w \\cdot x + b) $$\n",
    "\n",
    "where $w \\in \\mathcal{R}^k$, $b$ is a scalar bias, $x \\in \\mathcal{R}^k$, we reparameterize the $w$ as:\n",
    "\n",
    "$$ w = \\frac{g}{\\| v \\|} v $$\n",
    "\n",
    "where $g$ is a scaler, $\\| v \\|$ denotes the Euclidean norm of vector $v$. We now have $\\| w \\| = g$.\n",
    "\n",
    "Forthermore, we can reparameterize $g$ as $g = e^s$, where $s$ is a log-scale parameter to learn by SGD. However, empirically, the authors **did not** find this to be an advantage, and optimization was slightly slower.\n",
    "\n",
    "### Comparison to Batch Norm\n",
    "\n",
    "In special cases weight norm is the same as batch norm, see paper section 2.2 for detail.\n",
    "\n",
    "For CNNs, weight normalization is often much faster computationally, it is also non-stochastic, not affected by batch size. It can be viewed as a cheaper and less noisy approximation to batch norm. Equivalence does not hold for deeper architectures.\n",
    "\n",
    "### Data-Dependent Initialization of Parameters\n",
    "\n",
    "Important to properly initialize our parameters. Authors proposed to sample the elements of $v$ from a simple distribution with fixed scale, such as a normal distribution with zero mean and standard deviation of 0.05.\n",
    "\n",
    "This only works where batch norm is applicable, for RNNs and LSTMs, need to resort to standard initilization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='highway'></a>\n",
    "## Highway Networks\n",
    "\n",
    "[Summary Paper](https://arxiv.org/abs/1505.00387)\n",
    "\n",
    "[Full Paper](https://arxiv.org/abs/1507.06228)\n",
    "\n",
    "\n",
    "Highway networks enables the optimization of the networks with virtually arbitary depth. This is accomplished through the use of a **learned gating machanism** for regulating information flow wihch is inspired by LSTM.\n",
    "\n",
    "The paper shows that the optimization of highway network is virtually independent of depth. Used to train a 900-layer network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plain feedforward network of $L$ layers with $H$ as a non-linear transform function, ignoring layer index:\n",
    "\n",
    "$$ y = H(x, W_H) $$\n",
    "\n",
    "For a highway network, the paper adds two non-linear transform: \n",
    "* Tranform gate, $T(x W_T)$\n",
    "* Carry gate, $C(x, W_C)$\n",
    "\n",
    "$$ y = H(x, W_H) \\cdot T(x, W_T) + x \\cdot C(x, W_C) $$\n",
    "\n",
    "The paper sets $C = 1 - T$\n",
    "\n",
    "The **dimensionality** of $x$, $y$, $H(x, W_H)$ and $T(x, W_T)$ must be the same for the equation above to hold.\n",
    "\n",
    "If size of the representation needs to be changed, two ways:\n",
    "\n",
    "1. replace $x$ with $\\tilde{x}$ obtained by suitably sub-sampling or zero-padding $x$\n",
    "2. Use a plain layer without highway to change dimensionality and then continue with stacking highway layers. This is what the paper used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform gate** is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "T(x) &= \\sigma(W_T^T x + b_T) \\\\\n",
    "\\sigma(x) &= \\frac{1}{1 + e^{-x}}, x \\in \\mathbb{R}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$b_T$ can be initialized with a negative number (e.g. -1, -3, etc) such that the network is biased initially towards **carry** behaviour. The paper found that during training, $b_T$ actually got further negative, this behavour suggests that the strong negative biases at low depths are not used to shut down the gates, but to make them more selective. \n",
    "\n",
    "$W_H$ can be initialized with various zero mean distributins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "<a id='densenet'></a>\n",
    "## Densely Connected Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bootstrap'></a>\n",
    "# Bootstrap\n",
    "\n",
    "**My current thinking** is that perhaps it’s best to look at multiple measures, large discrepancies would point to something odd. Otherwise, the differences between the methods are mostly minor for practical use. Particularly comparing to other market uncertainties.\n",
    "\n",
    "\n",
    "Efron: **Accelerated Bootstrap intervals (BCa)** has better estimates of confidence intervals with some assumptions. makes certain assumptions, see below\n",
    " \n",
    "[Paper](https://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.ss/1032280214)\n",
    "\n",
    "[Slides](https://faculty.washington.edu/heagerty/Courses/b572/public/GregImholte-1.pdf)\n",
    "\n",
    "[Stack Exchange Answer](https://stats.stackexchange.com/questions/19340/bootstrap-based-confidence-interval)\n",
    "\n",
    "## `arch`\n",
    "Python package `arch` has studentized/bias-corrected intervals for bootstrap results.See [doc](http://arch.readthedocs.io/en/latest/bootstrap/confidence-intervals.html#bias-corrected-and-accelerated-bca)\n",
    "\n",
    "Discovered a minor bug in `conf_int(method=’bca’)`, see [issue](https://github.com/bashtage/arch/issues/193)\n",
    "\n",
    "\n",
    "## `scikits-bootstrap`\n",
    "\n",
    "Another implementation, see comments in [code](https://github.com/cgevans/scikits-bootstrap/blob/master/scikits/bootstrap/bootstrap.py)\n",
    "\n",
    "\n",
    "## Block Bootstrap\n",
    "\n",
    "**Politis, White, 2004. Automatic Block-Length Selection for the Dependent Bootstrap**\n",
    "\n",
    "Code in R and Matlab can be found on this [page](http://public.econ.duke.edu/~ap172/) by Prof. Andrew Patton, as well as a correction in 2009 to the original paper.\n",
    "\n",
    "Main points from the paper:\n",
    "\n",
    "**Stationary Bootstrap (SB)** is less accurate than **Circular Block Bootstrap (CB)** for estimating $\\sigma^2_{\\infty}$. Although they have similar bias the SB has higher variance due to the additional randomization involved in drawing the random block size.\n",
    "\n",
    "SB is **less sensitive** to block size mis-specification compared to CB and/or the moving block bootstrap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1707.05589'></a>\n",
    "\n",
    "# On the State of the Art of Evaluation in Neural Language Models\n",
    "\n",
    "[paper](https://arxiv.org/abs/1707.05589)\n",
    "\n",
    "This paper tuned LSTM and Recurrent Highway Networks to beat many more complex models in natural language modeling. A lot of dropout techniques are used here. \n",
    "\n",
    "Instead of comparing models based on the number of hidden units, comparison is done based on **total number of trainable parameters.**\n",
    "\n",
    "Dropout:\n",
    "* input dropout\n",
    "* intra-layer dropout\n",
    "* down-projected outputs / output dropout\n",
    "\n",
    "Things to learn about:\n",
    "\n",
    "**Variational Dropout**: Gal and Ghahramani 2016, [link](https://arxiv.org/abs/1512.05287)\n",
    "\n",
    "**Recurrent Dropout**: Semeniuta et al. 2016. [link](https://arxiv.org/abs/1603.05118)\n",
    "\n",
    "**Using mean-field approximation for dropout at test time**. \n",
    "\n",
    "**Truncated backpropagation**: Training used Adam/batch size 64/truncated backprop performed with 50 time steps.\n",
    "\n",
    "Hyperparameter tuning was performed using a black-box tuner based on **batched GP bandits** (Desautels et al. 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clustering_ts'></a>\n",
    "## Clustering Financial Time Series: how long is enough?\n",
    "\n",
    "[paper](https://arxiv.org/abs/1603.04017)\n",
    "\n",
    "Looked at Hierarchical Correlation Block Model (HCBM) with single-linkage, complete-linkage, average-linkage, Ward, McQuitty, Median, Centroid algos.\n",
    "\n",
    "Spearman rank correlation is more robust than Pearson correlation when there is:\n",
    "* noise\n",
    "* variables have infinite second moment.\n",
    "\n",
    "Their conclusion was **Ward** method converges faster than others such as single/average-linkage, converges around 250 observations for 256 assets with correlation matrix simiar to Figure 2 in this paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='tcn'></a>\n",
    "\n",
    "## Temporal Convolutional Networks (TCN)\n",
    "\n",
    "[paper](https://arxiv.org/abs/1803.01271), code available on [github](https://github.com/locuslab/TCN). Here is a description of its basic architecure. \n",
    "\n",
    "Two principles: \n",
    "\n",
    "* network produces the same length as the input\n",
    "* there can be no leakage from the future into the past\n",
    "\n",
    "TCN uses **1-D full convolution + causal convolution**, meaning an output at time `t` is only convolved with elements from time `t` and earlier in the previous layers. \n",
    "\n",
    "* Hidden layer is the **same length as the input layer**.\n",
    "* zero padding of length `k-1` where `k` is the kernel size, keeping subsequent layers the same size as the previous ones.\n",
    "\n",
    "In the `tcn.py`, `Chomp1d()` is essentially a layer that chops off the extra padding added to the end of the inputs to ensure **causal convolution**. \n",
    "\n",
    "**Dilated convolution** is used here, starting with the input layer with dilation $d = 1$, i.e. no dilation and increase dilation **exponentially** with the depth of the network (i.e. $d = \\mathcal{O}(2^i)$ where $i$ is the layer index).\n",
    "\n",
    "* **Same padding** size for layer `i`: `padding = (k - 1) * dilation_size`.\n",
    "* **Larger dilation** enables an output at the top level to represent a **wider** range of inputs, thus increase the **receptive field** of the conv net. \n",
    "* 3 ways to **increase** receptive field: \n",
    "    1. larger filter size `k`\n",
    "    2. larger dilation, set `d=2**i` for layer `i`\n",
    "    3. more of layers, in the code the number of layers is set to the number of channels.\n",
    "\n",
    "Ensures:\n",
    "\n",
    "1. some filter hits each input within the effective history,\n",
    "2. allowing for an extremely large effective history using deep network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/tcn.png' width='800'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TemporalBlock` in code\n",
    "\n",
    "**Residual Connection** like ResNet, with weight normalization. Unlike ResNet, the input and output of TCN can have different length, therefore authors use a 1x1 convolution to ensure that **element-wise** addition receives tensors of the same shape (figure b, c above).\n",
    "\n",
    "**Weight normalization** [above](#weight_norm) from [Salimans & Kingma 2016](https://arxiv.org/abs/1602.07868). Pytorch: `torch.nn.utils.weight_norm()` [docs](http://pytorch.org/docs/master/nn.html#weight-norm)\n",
    "\n",
    "**Spatial dropout** from [Srivastava et al 2014](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf). Pytorch: `torch.nn.Dropout2d()` [docs](http://pytorch.org/docs/master/nn.html#torch.nn.Dropout2d)\n",
    "\n",
    "Authors demostrated TCN has longer memory than LSTM and GRU in 2 tasks. \n",
    "\n",
    "#### Construction\n",
    "\n",
    "Input shape is `(N, C, L)`, where:\n",
    "* `N` is number of samples\n",
    "* `C` is number of channels, or number of feature dimensions\n",
    "* `L` is sequence length of all channels/features.\n",
    "\n",
    "For the `Conv1d` layers, **input** and **output** sizes are set to the **number of channels** for input and output. \n",
    "\n",
    "In the paper, padding is done such as input and output sequence lengths are matched.\n",
    "\n",
    "`Chomp1d` applied after `Conv1d` to ensure causal convolution, `chomp_size = padding`.\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "Forward flow is as follows: \n",
    "\n",
    "```\n",
    "z = conv1d -> chomp1d(padding) -> relu -> dropout -> conv1d -> chomp1d(padding) -> relu -> dropout\n",
    "\n",
    "if input_channel != output_channel:\n",
    "    # map z to output_channels\n",
    "    r = conv1d(z, input_channels, output_channels, kernel_size=1)\n",
    "    residual = r(z)\n",
    "    out = relu(z + residual)\n",
    "else:\n",
    "    out = z\n",
    "\n",
    "return out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape is (N, in_channels, L)\n",
    "# N: number of samples\n",
    "# in_channels: or number of features\n",
    "# L: feature length\n",
    "x = torch.randn(2, 1, 5)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  0.2089 -0.2274  0.0779 -0.8448 -0.0247\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.3559 -0.5786 -0.2676 -1.2133  2.0995\n",
       "[torch.FloatTensor of size 2x1x5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv1d(in_channels=1, out_channels=4, kernel_size=3, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = m(Variable(x, requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.3220  0.2502  0.4168  0.3306  0.6797  0.3565  0.3297\n",
       "  0.2908  0.3632  0.1106  0.3824 -0.0922  0.6123  0.2945\n",
       "  0.0077 -0.2472  0.0814 -0.5939  0.1302 -0.4114 -0.1000\n",
       " -0.1645 -0.4203 -0.2044 -0.4503  0.1377  0.2141 -0.2240\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.3170  0.2012  0.5718  0.4940  0.7666 -0.5190  0.2869\n",
       "  0.2952  0.4129 -0.1018  0.3707 -0.0417  1.6270 -0.5545\n",
       "  0.0768 -0.4474  0.0599 -0.8202  1.0825 -1.0621  0.7218\n",
       " -0.1136 -0.6156 -0.2242 -0.2223  1.2371 -0.6594 -1.3268\n",
       "[torch.FloatTensor of size 2x4x7]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is padded by 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "(0 ,.,.) = \n",
       " -0.0202 -0.4157 -0.0345\n",
       "\n",
       "(1 ,.,.) = \n",
       " -0.3997  0.4084  0.0296\n",
       "\n",
       "(2 ,.,.) = \n",
       "  0.3869 -0.2392  0.4698\n",
       "\n",
       "(3 ,.,.) = \n",
       " -0.5192 -0.5013  0.3462\n",
       "[torch.FloatTensor of size 4x1x3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.034489214420318604"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight.data[0,0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 0.3292\n",
       " 0.2847\n",
       "-0.0904\n",
       "-0.2368\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.3220\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.mul(x[0, 0, :1], m.weight.data[0, 0, 2])) + m.bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3220287561416626"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Chomp1d()` in the TCN code is to make sure that we chop off the padding on the right to ensure causual convolution. \n",
    "\n",
    "See example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chomp = Chomp1d(padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.3220  0.2502  0.4168  0.3306  0.6797\n",
       "  0.2908  0.3632  0.1106  0.3824 -0.0922\n",
       "  0.0077 -0.2472  0.0814 -0.5939  0.1302\n",
       " -0.1645 -0.4203 -0.2044 -0.4503  0.1377\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.3170  0.2012  0.5718  0.4940  0.7666\n",
       "  0.2952  0.4129 -0.1018  0.3707 -0.0417\n",
       "  0.0768 -0.4474  0.0599 -0.8202  1.0825\n",
       " -0.1136 -0.6156 -0.2242 -0.2223  1.2371\n",
       "[torch.FloatTensor of size 2x4x5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last two columns of y chopped off.\n",
    "chomp(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='layer_norm'></a>\n",
    "\n",
    "# Layer Normalization\n",
    "\n",
    "[2016 Paper](https://arxiv.org/abs/1607.06450)\n",
    "\n",
    "## Notations\n",
    "\n",
    "Given the $l^{th}$ hidden layer: \n",
    "\n",
    "* $w^l$ be the weight vector, $w^l_i$ is the wieght for the $i^{th}$ hidden unit.\n",
    "* $h^l$ is the bottom-up input, \n",
    "* $b^l$ is the bias,\n",
    "* let $a^l$ be the vector of the summed inputs to the neuron in that layer:\n",
    "\n",
    "$$ a^l_i = w^l_i h^l $$\n",
    "$$ h^{l+1} = f(a^l_i + b^l_i) $$\n",
    "\n",
    "Where $f()$ is an element-wise non-linear function. \n",
    "\n",
    "For [Batch Norm](./andrew_ng/DeepLearning.ai.ipynb#batchnorm), the normalization is done over the **entire** training batch due to computational reasons. This puts constraints on the size of a minibatch and it is hard to apply to RNN.\n",
    "\n",
    "## Layer Norm\n",
    "\n",
    "Becaue the changes in the output of one layer will tend to cause highly correlated changes in the summed inputs to the next layer, especially with ReLU units whose output can change by a lot, ***Layer norm** statistics are computed over all the hidden units in the same layer as follows:\n",
    "\n",
    "* $H$ number of hidden units in a layer\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu^l &= \\frac{1}{H} \\sum^H_{i=1} a^l_i \\\\\n",
    "\\sigma^l &= \\sqrt{\\frac{1}{H}\\sum^H_{i=1}\\big( a^l_i - \\mu^l\\big)^2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Normalization happens within the hidden layer, all hidden units in the same layer share the same $mu$ and $sigma$, but different training cases have different normalization terms.\n",
    "\n",
    "**Unlike** batch norm, layer norm is:\n",
    "\n",
    "* does not impose any constraint on the size of minibatch\n",
    "* can be used in a pure online regime with batch size 1\n",
    "\n",
    "For RNN, layer norm works as follows\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "a^t &= W_{hh} h^{t-1} + W_{xh} x^t \\\\\n",
    "h^t &= f \\bigg[ \\frac{g}{\\sigma^t} \\odot \\big( a^t - \\mu^t \\big) + b \\bigg] \\\\\n",
    "\\mu^t &= \\frac{1}{H} \\sum^H_{i=1} a^t_i \\\\\n",
    "\\sigma^t &= \\sqrt{\\frac{1}{H}\\sum^H_{i=1}\\big( a^t_i - \\mu^t\\big)^2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $b$ is bias parameter, same dimension as $h^t$\n",
    "* $g$ is gain parameter, same dimension as $h^t$\n",
    "\n",
    "Layer norm for RNN results in much more stable hidden-to-hidden gradient dynamics (vs. exploding/vanishing gradients).\n",
    "\n",
    "Section 4 of the paper discusses related work including weight norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/layer_norm_comp.png' width=800/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
