{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on random stuff I read about..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Clustering\n",
    "\n",
    "[post](http://nicolas.kruchten.com/content/2018/02/seriation/)\n",
    "\n",
    "R package `seration`. Demo code [here](https://github.com/nicolaskruchten/seriation)\n",
    "\n",
    "Talked about 3 methods:\n",
    "\n",
    "1. Agglomerative clustering,\n",
    "2. Optimal Leaf Ordering (starts with agglomerative clustering output then reorder branches of the dendrogram so as to minimize the sum of dissimilarities between adjacent leaves),\n",
    "3. Traveling salesman (find the order of rows that minimizes the sum of dissmilarities, unconstrained by the clustering tree).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Importance for Random Forest Feature Importance\n",
    "\n",
    "See this [post](http://parrt.cs.usfca.edu/doc/rf-importance/index.html), [github](https://github.com/parrt/random-forest-importances)\n",
    "\n",
    "`sklearn` Random Forest feature importance and `R`'s default Randome Forest feature importance strategies are **biased**.\n",
    "\n",
    "Solution is to compute **permutation importance** from Breiman and Cutler. Existing packages:\n",
    "\n",
    "* Python: `rfpimp` through `pip`\n",
    "* R: use `importance=T` in random forest constructor then `type=1` and `scale=F` in `R`'s `importance()` function. \n",
    "\n",
    "Feature importance will only be reliable **if your model is trained with suitable hyper-parameters**.\n",
    "\n",
    "Permutation importance works for all models, not just random forests. The procedure is as follows:\n",
    "\n",
    "1. Train the model as usual\n",
    "2. Record a baseline: score the model by passing a validation or test set.\n",
    "3. For each feature (columns), permute the column values, compute the same score. \n",
    "4. The importance of a feature is **the difference of scores between the baseline and the drop in score after permutation**. \n",
    "\n",
    "The importance metrics here are **not** normalized and do not sum to 1. The specific values of importance do not matter, what matters is the **relative predictive strength**, i.e. ranking.\n",
    "\n",
    "A more direct and accurate strategy is the **drop-column importance**. This requires establishing a baseline, and then drop a feature column and **re-train** the model. Clearly, this is more computationally intensive. The importance measure is the drop of score from the baseline, as before. \n",
    "\n",
    "Here's the code snippet from the post.\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "def permutation_importances(rf, X_train, y_train, metric):\n",
    "    baseline = metric(rf, X_train, y_train)\n",
    "    imp = []\n",
    "    for col in X_train.columns:\n",
    "        save = X_train[col].copy()\n",
    "        X_train[col] = np.random.permutation(X_train[col])\n",
    "        m = metric(rf, X_train, y_train)\n",
    "        X_train[col] = save\n",
    "        imp.append(baseline - m)\n",
    "    return np.array(imp)\n",
    "    \n",
    "\n",
    "def dropcol_importances(rf, X_train, y_train):\n",
    "    rf_ = clone(rf)\n",
    "    rf_.random_state = 999\n",
    "    rf_.fit(X_train, y_train)\n",
    "    baseline = rf_.oob_score_\n",
    "    imp = []\n",
    "    for col in X_train.columns:\n",
    "        X = X_train.drop(col, axis=1)\n",
    "        rf_ = clone(rf)\n",
    "        rf_.random_state = 999\n",
    "        rf_.fit(X, y_train)\n",
    "        o = rf_.oob_score_\n",
    "        imp.append(baseline - o)\n",
    "    imp = np.array(imp)\n",
    "    I = pd.DataFrame(\n",
    "            data={'Feature':X_train.columns,\n",
    "                  'Importance':imp})\n",
    "    I = I.set_index('Feature')\n",
    "    I = I.sort_values('Importance', ascending=True)\n",
    "    return I\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
