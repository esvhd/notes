{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression / Stats Notes\n",
    "\n",
    "* [Non-IID Error Newey West](#newey_west)\n",
    "* [Logistic Regression](#logistic)\n",
    "* [Bayesian Posterior Odds](#posterior_odds)\n",
    "* [Statistical Rethinking](#rethinking)\n",
    "    * [K-L Divergence](#kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS\n",
    "\n",
    "For OLS regression problems, assume model $y = X\\beta + \\varepsilon$, we have solution for $\\beta$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ \\hat{\\beta} &= (X^{T}X)^{-1}X^{T}y\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let $\\hat{y}$ be the model predicted value of $y$.\n",
    "\n",
    "## Regression Metrics\n",
    "\n",
    "### **RSS**, Residual Sum of Squares, or sometime known as Sum of Square Erros, **SSE**\n",
    "\n",
    "$$RSS = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n}e_i^{2}$$\n",
    "\n",
    "### **MSE**, Mean Sequare Error, or **RSE**, Residual Standard Error\n",
    "\n",
    "For $X$ in the dimention of $(n, p)$, i.e. $n$ observations, $p$ features (degree of freedom = $p + 1$, assuming there is an intercept):\n",
    "\n",
    "$$MSE = \\frac{RSS}{n - p - 1}$$\n",
    "\n",
    "$$RSE = RMSE = \\sqrt{MSE}$$\n",
    "\n",
    "**R code**, degree of freedum is given by: `summary(model)$sigma`\n",
    "\n",
    "### **TSS**, Total Sum of Squares\n",
    "\n",
    "$$\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n}y_i$$\n",
    "\n",
    "$$TSS = \\sum_{i=1}^{n}(y_i - \\bar{y}_i)^2$$\n",
    "\n",
    "### $R^2$, Adjusted $R^2$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ R^2 &= \\frac{TSS - RSS}{TSS} = 1 - \\frac{RSS}{TSS} \\\\\n",
    "\\ \\\\\n",
    "\\ Adjusted.R^2 &= 1 - \\frac{RSS/(n-p-1)}{TSS/(n-1)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "### F-test of significance of all parameters. ISLR, p77\n",
    "\n",
    "Look up for p-value in F-table for degree of freedum of $(p, n-p-1)$ (columns, rows). \n",
    "\n",
    "NULL hypothesis $H_0$ is that all parameters are zero.\n",
    "\n",
    "$$F = \\frac{(TSS-RSS) / p}{RSS / (n-p-1)}$$\n",
    "\n",
    "### F-test of two models\n",
    "\n",
    "Consider a large model of $p$ features, and a smaller model of a subset of $p$ features, say $q$ features. F-test can be used to see which model is better. \n",
    "\n",
    "NULL hypothesis $H_0$ is that the smaller model is better. \n",
    "\n",
    "$$F = \\frac{(RSS_q - RSS_p)/q}{RSS_p / (n-p-1)}$$\n",
    "\n",
    "\n",
    "### $R^2$ and Correlation\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ R^2 = \n",
    "\\begin{cases}\n",
    "p = 1, \\text{corr($y$, $x$)^2} \\\\\n",
    "p > 1, \\text{corr($y$, $\\hat{y}$)^2} \\\\\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection Metrics for p > 1\n",
    "\n",
    "Model selection should be done using metrics on **test data, not training data**.\n",
    "\n",
    "### $C_{p}$, choose model with lowest value\n",
    "\n",
    "$$C_{p} = \\frac{1}{n}(RSS + 2p\\hat{\\sigma}^2)$$\n",
    "\n",
    "Where $\\hat{\\sigma}^2$ is the estimated residual variance.\n",
    "\n",
    "\n",
    "### AIC, lower value better\n",
    "\n",
    "$$AIC = \\frac{1}{n\\hat{\\sigma}^2}(RSS + 2p\\hat{\\sigma}^2)$$\n",
    "\n",
    "### BIC, places heavier penalty on models with higher dimensions. \n",
    "\n",
    "$$BIC = \\frac{1}{n}(RSS + \\log{(n)}p\\hat{\\sigma}^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accurancy of Sample Mean $\\hat{\\mu}$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ \\hat{SE}(\\hat{\\mu}) &= \\frac{\\sigma^{2}}{n} \\\\\n",
    "\\ \\hat{\\mu} &= \\frac{1}{n}\\sum_{i=1}^{n}x_i \\\\\n",
    "\\ \\sigma^2 &= variance(x) \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Principal, ISLR, p89\n",
    "\n",
    "If we include an interaction in a model, we should also include the main effects, even if the p-value associated with their coefficient are not significant. E.g. if $X_1 \\times X_2$ seems important, the model should include both $X_1$ and $X_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals, p = 1\n",
    "\n",
    "CI - Confidience Interval of model prediction **on average**, where $\\alpha$ is the probability, e.g. 95%:\n",
    "\n",
    "$$CI=\\hat{y}_n \\pm t_{(\\alpha/2, n-p-1)} \\times \\sqrt{MSE * (\\frac{1}{n} + \\frac{(x_h - \\bar{x})^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2})}$$\n",
    "\n",
    "$t_{(\\alpha/2, n-p-1)}$ is based on Normal distrubtion table.\n",
    "\n",
    "Conditions for CI\n",
    "\n",
    "1. $x_h$ is within the range of training data, i.e. within scope of the model\n",
    "2. **LINE**: Linear, Independent errors, normal errors, equal variance. Still works if error is approximately Normal. Or, if $n$ is large, error can deviate substantially from normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Interval, p = 1\n",
    "\n",
    "PI - Prediction Interval, for point predictions, where $\\alpha$ is the probability.\n",
    "\n",
    "$$PI = \\hat{y}_h \\pm t_{(\\alpha/2, n-p-1)} \\times \\sqrt{MSE \\times (1 + \\frac{1}{n} + \\frac{(x_h - \\bar{x})^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2})}$$\n",
    "\n",
    "$t_{(\\alpha/2, n-p-1)}$ is based on Normal distrubtion table.\n",
    "\n",
    "Conditions for PI\n",
    "\n",
    "1. $x_h$ is within the range of training data, i.e. within scope of the model\n",
    "2. **LINE**: Linear, Independent errors, normal errors, equal variance. Strongly depends on errors being normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence & Prediction Intervals where p > 1\n",
    "\n",
    "Reference:\n",
    "\n",
    "* https://onlinecourses.science.psu.edu/stat501/node/314\n",
    "\n",
    "* https://onlinecourses.science.psu.edu/stat501/node/315\n",
    "\n",
    "Let $X_n = (1, x_{n,1}, x_{n, 2}, \\ldots, x_{n, p})^T$, $X_h$ is an observation.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ CI &= \\hat{y}_h \\pm t_{(\\alpha/2, n-p-1)} \\times SE(\\hat{y}_h) \\\\\n",
    "\\ \\\\\n",
    "\\ PI &= \\hat{y}_h \\pm t_{(\\alpha/2, n-p-1)} \\times \\sqrt{MSE + SE(\\hat{y}_h)^2} \\\\\n",
    "\\ \\\\\n",
    "\\ SE(\\hat{y}_h)^2 &= MSE \\times X_{h}^T(X^{T}X)^{-1}X_{h} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "### Python \n",
    "http://statsmodels.sourceforge.net/devel/generated/statsmodels.regression.linear_model.OLSResults.html\n",
    "\n",
    "Confidence Interval: ```OLSResults.conf_int()```\n",
    "\n",
    "Prediction Interval: \n",
    "http://markthegraph.blogspot.de/2015/05/using-python-statsmodels-for-ols-linear.html\n",
    "\n",
    "```{python}\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "\n",
    "prstd, iv_l, iv_u = wls_prediction_std(re)\n",
    "```\n",
    "\n",
    "See source:\n",
    "https://github.com/statsmodels/statsmodels/blob/master/statsmodels/sandbox/regression/predstd.py\n",
    "\n",
    "### R\n",
    "\n",
    "`predict` or `predict.lm`. check out `help(predict.lm)` and see `internal` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance of OLS $\\hat{\\beta}$\n",
    "\n",
    "Let:\n",
    "\n",
    "$$ \\sigma^2 = MSE = RSE^2 $$\n",
    "\n",
    "### I.I.D Errors\n",
    "\n",
    "Based on OLS model formula above, subsituting in for $y$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ \\hat{\\beta} & = (X^{T}X)^{-1}X^{T}y \\\\\n",
    "\\ &= (X^{T}X)^{-1}X^{T}(X\\beta + \\varepsilon) \\\\\n",
    "\\ &= (X^{T}X)^{-1}X^{T}X\\beta + (X^{T}X)^{-1}X^{T}\\varepsilon \\\\\n",
    "\\ &= \\beta + (X^{T}X)^{-1}X^{T}\\varepsilon\\\\\n",
    "\\ \\\\\n",
    "\\ var(\\hat{\\beta}) &= \\mathbb{E}[(X^{T}X)^{-1}X^{T}\\varepsilon\\varepsilon^{T}X(X^{T}X)^{-1}] \\\\\n",
    "\\ &= (X^{T}X)^{-1}\\mathbb{E}[X^{T}\\varepsilon\\varepsilon^{T}X](X^{T}X)^{-1}\\\\\n",
    "\\ &= (X^{T}X)^{-1}X^{T}\\mathbb{E}[\\varepsilon\\varepsilon^{T}]X(X^{T}X)^{-1}\\\\\n",
    "\\ \\because \\varepsilon &\\sim \\mathcal{N}(0, \\sigma^2) \\\\\n",
    "\\ \\therefore \\mathbb{E}[\\varepsilon\\varepsilon^{T} \\mid X] &= \\Omega = \\sigma^2 I \\\\\n",
    "\\ &= (X^{T}X)^{-1}X^{T}\\Omega X(X^{T}X)^{-1}\\\\\n",
    "\\ &= \\sigma^{2}(X^{T}X)^{-1}X^{T}X(X^{T}X)^{-1}\\\\\n",
    "\\ var(\\hat{\\beta}) &= \\sigma^{2}(X^{T}X)^{-1}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### I.N.I.D Errors (Heteroskedasticity)\n",
    "\n",
    "To deal with uncorrelationed residuals\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ var(\\hat{\\beta}) &= (X^{T}X)^{-1}X^{T}X\\mathbb{E}[\\varepsilon\\varepsilon^{T}](X^{T}X)^{-1}\\\\\n",
    "\\ \\because \\mathbb{E}[\\varepsilon\\varepsilon^{T}] &= \\sigma^{2}\\Omega \\\\\n",
    "\\ var(\\hat{\\beta}) &= (X^{T}X)^{-1}X^{T}\\sigma^{2}\\Omega X(X^{T}X)^{-1}\\\\\n",
    "\\ var(\\hat{\\beta}) &= \\sigma^{2}(X^{T}X)^{-1}X^{T}\\Omega X(X^{T}X)^{-1}\\\\\n",
    "\\ \\therefore \\hat{\\beta} &\\sim \\mathcal{N}(\\beta, \\sigma^{2}(X^{T}X)^{-1}X^{T}\\Omega X(X^{T}X)^{-1})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### N.I.N.I.D Errors (HAC)\n",
    "\n",
    "To deal with correlated residuals, use Newey West. See video below for details and Greene's book, p517 - p518.\n",
    "\n",
    "https://www.youtube.com/watch?v=HznGehi6xNQ \n",
    "\n",
    "**Newey West essentially has a modified / weighted variance-covariance matrix $\\Omega_{NW}$.**\n",
    "\n",
    "Essentially applying weights $\\omega$ diagonally to $\\Omega$, example:\n",
    "\n",
    "$$\n",
    "\\Omega_{NW} = \n",
    " \\begin{pmatrix}\n",
    "  e_{1}e_{1} & \\omega_{1}e_{1}e_{2} & \\omega_{2}e_{1}e_{3} & 0 & \\cdots & 0 \\\\\n",
    "  \\omega_{1}e_{1}e_{2} & e_{2}e_{2} & \\omega_{1}e_{2}e_{3} & \\omega_{2}e_{2}e_{4} & \\cdots & 0 \\\\\n",
    "  \\omega{2}e_{1}e_{3} & \\omega_{1}e_{2}e_{3} & e_{3}e_{3} & \\omega_{1}e_{3}e_{4} & \\cdots & 0 \\\\\n",
    "  0 & \\omega_{2}e_{2}e_{4} & \\omega_{1}e_{3}e_{4} & e_{4}e_{4} & \\cdots & 0 \\\\\n",
    "  \\vdots  & \\vdots  & \\vdots & \\vdots & \\ddots & \\vdots  \\\\\n",
    "  0 & 0 & 0 & \\cdots &\\omega_{1}e_{n-1}e_{n} & e_{n}e_{n}\n",
    " \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "With $0 < \\omega_1 < \\omega_2 < \\cdots < \\omega_n < 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='newey_west'></a>\n",
    "### Newey West \n",
    "\n",
    "http://stackoverflow.com/questions/23420454/newey-west-standard-errors-for-ols-in-python\n",
    "\n",
    "In `R`, `NeweyWest()` in the `sandwich` package use Newey West 1994 paper to automatically select the lag. \n",
    "\n",
    "In `Python`, currently there isn't a way to automatically select the lag. Some python packages, such as `arch`, use a default value of $4(n/100)^{2/9}$ where $n$ is the length of data, i.e. nobs.\n",
    "\n",
    "**`R` code to test $\\hat{\\beta} == 0$ with Newey West vcov matrix for correlated residuals**:\n",
    "\n",
    "```{R}\n",
    "library(lmtest)\n",
    "library(sandwich)\n",
    "\n",
    "lm.fit <- lm(y~x)\n",
    "coeftest(lm.fit, vcov. = NeweyWest)\n",
    "\n",
    "```\n",
    "\n",
    "Or manually:\n",
    "\n",
    "```{R}\n",
    "lm.fit <- lm(y~x)\n",
    "# IID case\n",
    "# std_err <- sqrt(diag(vcov(lm.fit)))\n",
    "std_err <- sqrt(diag(NeweyWest(lm.fit)))\n",
    "tstat <- coef(lm.fit) / std_err\n",
    "p_vals <- pt(abs(tstat), df=df.residuals(lm.fit), lower.tail=FALSE)\n",
    "```\n",
    "\n",
    "** `R` code to get $var(\\hat{\\beta})$ **:\n",
    "\n",
    "```\n",
    "var_beta <- vcov(lm.fit)\n",
    "# or\n",
    "x <- lm.fit.matrix(~V1+V2, data=df)\n",
    "var_beta <- summary(lm.fit)$sigma^2 * solve(t(x) %*% x)\n",
    "```\n",
    "\n",
    "**`Python` code for Newey West**:\n",
    "\n",
    "```{python}\n",
    "ols = sm.ols(...).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "ols.summary()\n",
    "# or\n",
    "ols = sm.ols(...).fit()\n",
    "ols2 = ols.get_robustcov_results(cov_type='HAC',maxlags=1)\n",
    "ols2.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "Formulation $y = X\\beta + \\lambda I \\beta^{T}\\beta + \\varepsilon$.\n",
    "\n",
    "OLS should not be used when $n < p$, i.e. when nobs < no. of features.\n",
    "\n",
    "Generally when the relationship is close to linear, least square methods may have **high variance and low bias**. **Ridge regression outperforms when OLS estimates have high variance, or when $p > n$ as OLS cannot be used.**\n",
    "\n",
    "Unlike OLS, whose coefficents are **scale equivariant**, ridge regression coefficients can vary significantly when variables are scaled. **Therefore, it is best to apply ridge regresion after standardising the predictors to have standard deviation of 1**, see ISRL p217:\n",
    "\n",
    "$$ \\tilde{x}_{ij} = \\frac{x_{ij}}{\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_{ij}-\\bar{x}_{j})}}$$\n",
    "\n",
    "Derivation of $\\hat{\\beta}$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ RSS &= (y - X\\beta)^{T}(y - X\\beta) + \\lambda I \\beta^{T} \\beta \\\\\n",
    "\\ &= y^{T}y - y^{T}X\\beta - \\beta^{T}X^{T}y + \\beta^{T}X^{T}X\\beta + \\lambda I \\beta^{T} \\beta \\\\\n",
    "\\frac{\\partial{RSS}}{\\partial{\\beta}} &= 0 - y^{T}X - X^{T}y + 2X^{T}X\\beta + 2\\lambda I \\beta  = 0\\\\\n",
    "\\therefore (2X^{T}X + 2\\lambda I)\\beta &= 2X^{T}y \\\\\n",
    "\\ (X^{T}X + \\lambda I)\\beta &= X^{T}y \\\\\n",
    "\\ \\beta &= (X^{T}X + \\lambda I)^{-1}X^{T}y \\\\\n",
    "\\ \\\\\n",
    "\\ var(\\hat{\\beta}) & = \\sigma^{2}\\mathbb{W}(X^{T}X)\\mathbb{W} \\\\\n",
    "\\ \\mathbb{W} &= (X^{T}X + \\lambda I)^{-1} \\\\\n",
    "\\ Bias(\\hat{\\beta}) &= -\\lambda \\mathbb{W}\\beta \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Variance formula & useful links: \n",
    "\n",
    "http://web.as.uky.edu/statistics/users/pbreheny/764-F11/notes/9-1.pdf\n",
    "\n",
    "http://statweb.stanford.edu/~tibs/sta305files/Rudyregularization.pdf\n",
    "\n",
    "https://onlinecourses.science.psu.edu/stat857/node/155\n",
    "\n",
    "### Confidence & Prediction Intervals\n",
    "\n",
    "See:\n",
    "\n",
    "http://stats.stackexchange.com/questions/13329/calculate-prediction-interval-for-ridge-regression\n",
    "\n",
    "http://stackoverflow.com/questions/39750965/confidence-intervals-for-ridge-regression\n",
    "\n",
    "Due to the ridge being a biased estimator, Bootstrapping seems to be the best way to estimate prediction intervals here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge vs Laso, ISRL p224\n",
    "\n",
    "One does not dominate the other, use CV in practice to see which works better, depends on the true relationship in data.\n",
    "\n",
    "Ridge shrinks parameters by the same proportion.\n",
    "\n",
    "Lasso srhinks each OLS parameter by $\\lambda / 2$. Therefore any parameter less than $\\lambda / 2$ is shrunken to zero. This is known as **soft thresholding**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Diagnostics in `R`\n",
    "\n",
    "## LINE Conditions\n",
    "\n",
    "Reference: **R in Action**, summary of functions on p187.\n",
    "\n",
    "In `R`, you can examine **LINE** with `plot()`:\n",
    "\n",
    "```{R}\n",
    "fit <- lm(weight ~ height, data=women)\n",
    "par(mfrow=c(2, 2))\n",
    "plo(fit)\n",
    "```\n",
    "\n",
    "Many functions in `R`'s `car` package can help:\n",
    "\n",
    "* **L**: Linearity. Look at **Risidual vs Fitted values** plot, residual should be random, should not exhibit patterns.\n",
    "    * **Component plus residual plots** (aka partial residual plots), `crPlots()`.\n",
    "    * solution: transform **feature variables**, try `car::boxTidwell()` suggested power transforms. check for p-values for the variable to see if transform is needed.\n",
    "\n",
    "* **I**: Independence of errors. Can't tell from the plots. \n",
    "    * `durbinWatsonTest()`\n",
    "\n",
    "* **N**: Normality. Look at Q-Q plot. \n",
    "    * `qqPlot()`, plots the studentized residuals (aka studentized deleted residuals or jackknifed residuals) against a t-distribution with `n-p-2` degrees of freedom. (n - nobs, p - no. of features excluding intercept).\n",
    "    * `residplot()` in **R in Action** on page 189.\n",
    "    * solution: Transform **feature variables**. Use `car::powerTransform()`, check p-value for lambda(1) which has no transform to see if a transform is in fact needed.\n",
    "    \n",
    "* **E**: Equal variance / Homoscedasticity. Scale-location plot, sqrt(standardized residual) vs fitted values. \n",
    "    * `ncvTest()`, NULL hypothesis is constant variance. A significant result would support heterscedasticity. \n",
    "    * `spreadLevelPlot()`\n",
    "    * Counter-measure is to transform the **response** with `log()` or `sqrt()`.\n",
    "* **Global Test** package `gvlma`\n",
    "\n",
    "## Multicollinearity\n",
    "\n",
    "Use **Variance Inflation Factor**, `vif()` function in `car` package. General rules is $\\sqrt{vif} > 2$ indicates a multicollinearity problem (R in Action).\n",
    "\n",
    "See ISRL p101-102:\n",
    "\n",
    "VIF is the ratio of the variance $\\hat{\\beta}_j$ when fiting the full model divided by the variance of $\\hat{\\beta}_j$ if fit on its own. Minimum of VIF is 1. **VIF > 5 or 10 indicates problems.**\n",
    "\n",
    "$$ VIF(\\hat{\\beta}_{j}) = \\frac{1}{1 - R^{2}_{X_{j} \\mid X_{-j}}} $$\n",
    "\n",
    "$R^{2}_{X_{j} \\mid X_{-j}}$ is the $R^2$ from a regression of $X_j$ onto all other features. if $R^{2}_{X_{j} \\mid X_{-j}}$ is close to 1, collinearity is present. \n",
    "\n",
    "Two ways to correct for Multicollinearity:\n",
    "* drop one of the problematic features\n",
    "* combine the collinear features into one single feature.\n",
    "\n",
    "## Unusual Observations\n",
    "\n",
    "### Outliers\n",
    "\n",
    "`outlierTest()` - Bonferroni adjusted p-value for the largest absolute studentized residual. **The test needs to be repeated if the largest data point is removed to check for other outliers.**\n",
    "\n",
    "### High Leverage Points\n",
    "\n",
    "These are observations with unusual combination of predictor values, i.e. outliers with regards to other predictors.\n",
    "\n",
    "Compute **leverage statistics (aka. hat statistics)**, `hatvalues()` (**R in Action** p195, also see code plot that uses `identify()` function). \n",
    "\n",
    "In general a hat statistics greater than 0.2 or 0.3 should be examined.\n",
    "\n",
    "Formula from **An Introductino to Statistical Learning with Applications in R, (ISLR)**, p98:\n",
    "\n",
    "$$ h_i = \\frac{1}{n} + \\frac{(x - \\bar{x})^2}{\\sum_{i^{'}=1}^{n}(x_{i^{'}} - \\bar{x})^2} $$\n",
    "\n",
    "$1/n < h_i < 1$, average leverage of all observations is $(p+1)/n$. Any observations with leverage statistics greatly exceeds the average should be checked.\n",
    "\n",
    "In matrix form this is $H = X(X^{'}X)^{-1}X^{'}$, where $X$ is the design matrix, $h_{ii} = H_{ii}$ for $i^{th}$ data point.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Leverage_(statistics)\n",
    "\n",
    "### Influential Observations\n",
    "\n",
    "These have disproportional impact on the values of the model parameters. Identified by:\n",
    "* **Cook's distance (D stat)** greater than $4/(n-p-1)$. In `R`: `plot(fit, which=4, cook.level=cutoff)`\n",
    "* **Added variable plots**, `avPlots(fit, ask=FALSE, id.method='identify')` in `car`\n",
    "\n",
    "**An outlier that also has high leverage is particularly dangerous.** See **ISLR** p99.\n",
    "\n",
    "### Influence Plot\n",
    "\n",
    "Combines all the above into `car`'s `influencePlot(fit, id.method='identify')`.\n",
    "\n",
    "## Model Selection \n",
    "\n",
    "* Stepwise regression, `MASS::stepAIC()`\n",
    "* All subsets regression, `leaps::regsubsets()`\n",
    "* Cross validation, `bootstrap::crossval()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests\n",
    "\n",
    "ANOVA analysis is sensitive to outliers. Run `outlierTest()` before the analysis.\n",
    "\n",
    "### Equality of Variances\n",
    "\n",
    "* Barlett's test: `barlett.test()`\n",
    "* Fligner-Killeen: `fligner.test()`\n",
    "* Brown-Frosythe test: `HH::hov()`\n",
    "\n",
    "\n",
    "\n",
    "## Power Analysis\n",
    "\n",
    "**Power** is defined as: $1 - Prob(\\text{Type II Error})$, i.e. it is the probability of finding evidence to reject the NULL hypothesis (finding an effect is there).\n",
    "\n",
    "`pwr` package provides a list of power analysis tests. List of functions in **R in Action** page 242.\n",
    "\n",
    "Useful ones:\n",
    "\n",
    "* t-test: `pwr.t.test()`\n",
    "* correlation: `pwr.r.test()` \n",
    "* linear models: `pwr.f2.test()`\n",
    "\n",
    "# Permutation Test & Bootstrap\n",
    "\n",
    "Packages: \n",
    "\n",
    "* `coin` \n",
    "* `lmPerm`\n",
    "* `logregperm` permutation test for logistic regression\n",
    "* `glmperm` for GLM\n",
    "* `boot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCPR: Component-Component Plus Residual\n",
    "\n",
    "In multivariable regression, a Partial-Residual plot shows the relationship\n",
    "between an **independent variable** $X_i$ vs. **response** variable excluding\n",
    "the impact of $X_i$. I.e.:\n",
    "\n",
    "$$Residual + beta_i \\times X_i \\sim X_i$$\n",
    "\n",
    "CCPR generates a partial residual plot, plus a component plot (fitted line)\n",
    "for: $beta_i \\times X_i \\sim X_i$. Intention is to show where the fitted line would\n",
    "lie.\n",
    "\n",
    "Some explanation [here](http://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/ccpr.htm)\n",
    "\n",
    "Although they can often be useful, be aware that they can also fail to\n",
    "indicate the proper relationship. In particular, if $X_i$ is highly correlated\n",
    "with any of the other independent variables, the variance indicated by the\n",
    "partial residual plot can be much less than the actual variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logistic'></a>\n",
    "## Logistic Regression\n",
    "\n",
    "Based on ESL and ISLR books. \n",
    "\n",
    "ISLR notation here. The goal is to model probability using a **linear** model. However, probabilities don't have negative values, so need to model a response between 0 and 1. Hence the use of **logistic function** below.\n",
    "\n",
    "$$ p(X) = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}} $$\n",
    "\n",
    "Given that \n",
    "\n",
    "$$ 1 - p(X) = \\frac{1}{1 + e^{\\beta_0 + \\beta_1 X}} $$\n",
    "\n",
    "therefore:\n",
    "\n",
    "$$ \\frac{p(X)}{1 - p(X)} = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}} \\times (1 + e^{\\beta_0 + \\beta_1 X}) = e^{\\beta_0 + \\beta_1 X} $$\n",
    "\n",
    "$\\frac{p(X)}{1 - p(X)}$ is called the **odds**, takes the value of $[0, +\\infty]$. Take log on both sides gives:\n",
    "\n",
    "$$ \\log\\bigg(\\frac{p(X)}{1 - p(X)}\\bigg) = \\beta_0 + \\beta_1 X $$\n",
    "\n",
    "The LHS of the above equation is called the **log-odds** or **logit**. \n",
    "\n",
    "In **ISLR** the authors mentioned that multiple-calss logistic regression \"tend not to be used\" in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ESL** section 4.4 gives a formulation of a K-class logisitic regression problem. \n",
    "\n",
    "Define \n",
    "$$p(G=k \\mid X=x) = \\frac{\\exp\\big(\\beta_{k0} + \\beta^T_{k} x\\big)}{1 + \\sum^{K-1}_{l=1} \\exp\\big(\\beta_{l0} + \\beta^T_l x\\big)}$$ \n",
    "\n",
    "For $k = 1, \\cdots, K-1$. The $K^{th}$ class doesn't need to be modeled because all probabilities must sum to 1. The choice of which class becomes $K$ is also arbitrary as it does not affect the outcome. Hence we define:\n",
    "\n",
    "$$p(G=K \\mid X=x) = \\frac{1}{1 + \\sum^{K-1}_{l=1} \\exp\\big(\\beta_{l0} + \\beta^T_l x\\big)}$$\n",
    "\n",
    "With the above formulation, we can see that:\n",
    "\n",
    "$$\\sum^K_{j=1} \\big(p(G=j \\mid X=x)\\big) = \\frac{1 + \\sum^{K-1}_{l=1} \\exp\\big(\\beta_{l0} + \\beta^T_l x\\big)}{1 + \\sum^{K-1}_{l=1} \\exp\\big(\\beta_{l0} + \\beta^T_l x\\big)} = 1 $$\n",
    "\n",
    "And this shows that it does not matter which class we choose as the $K^{th}$ class. Therefore:\n",
    "\n",
    "$$\\log\\bigg(\\frac{p(G=j \\mid X=x)}{p(G=K \\mid X=x)}\\bigg) = \\log\\bigg[\\exp\\big(\\beta_{k0} + \\beta^T_{k} x\\big)\\bigg] = \\beta_{k0} + \\beta^T_{k} x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solved by maximum likelihood. The log-likelihood for N observations we aim to maximize is:\n",
    "\n",
    "$$ \\mathcal{l}(\\theta) = \\sum^N_{i=1}\\bigg( \\log [p_{g_i} (x_i; \\theta)] \\bigg) $$\n",
    "\n",
    "where $p_{g_i} (x_i; \\theta) = p(G=k \\mid X=x_i; \\theta)$. \n",
    "\n",
    "Generally solved with **Iterative Reweighted Least Squares** or **IRLS**. Althernatively, coordinate descent methods can be used. \n",
    "\n",
    "It is generally felt that logistic regression is a **safer, more robust** bet than Linear Discriminant Analysis (LDA) model, relying on **fewer** assumptions. LDA not robust to gross outliers (Gaussian assumption). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `R`, logistic regresoin is done using `glm()` with parameters `family=binominal`, e.g.:\n",
    "\n",
    "```\n",
    "glm.fit <- glm(Y ~ X0 + X2, data=d, family=binominal)\n",
    "summary(glm.fit)\n",
    "\n",
    "# show training data probabilities\n",
    "predict(glm.fit, type='response')\n",
    "\n",
    "# predict new data probabilities\n",
    "predict(glm.fit, new.data, type='response')\n",
    "```\n",
    "\n",
    "In addition, `R` package `glmnet` can fit very large logistic regression problems efficiently, typicall with CV and regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cross_entropy'></a>\n",
    "### Cross Entropy Loss\n",
    "\n",
    "For binary classification, given label $y$ and predicted probablility $p$, cross entropy loss is given by:\n",
    "\n",
    "$$ -y \\log(p) - (1 - y) \\log(1 - p) $$\n",
    "\n",
    "For multi-class classification of $M$ classes, cross entropy loss for $i^{th}$ training example is given by:\n",
    "\n",
    "$$ - \\sum^{M}_{c=1} y^i_{c} \\log(p^i_c) $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='posterior_odds'></a>\n",
    "\n",
    "## Bayesian Posterior Odds\n",
    "\n",
    "Given bayes theorem:\n",
    "\n",
    "$$ P(H \\mid D) = \\frac{P(D \\mid H) \\times P(H)}{P(D)} $$\n",
    "\n",
    "**Bayesian factor** $ = \\frac{P(D \\mid H)}{P(D \\mid \\bar{H})} $\n",
    "\n",
    "**Prior odds** $ = \\frac{P(H)}{P(\\bar{H})} $\n",
    "\n",
    "Trick is to compute **posterior odds**, which avoids knowing $P(D)$:\n",
    "\n",
    "$$\\frac{P(H \\mid D)}{P(\\bar{H} \\mid D)} = \\frac{P(D \\mid H) \\times P(H)}{P(D \\mid \\bar{H}) \\times P(\\bar{H})} $$\n",
    "\n",
    "Essentially, **posterior odds = bayesian factor * prior odds**.\n",
    "\n",
    "Note that $P(H \\mid D) + P(\\bar{H} \\mid D) = 1$, which shows that in the binary case, this is the same as the logistic regression odds. Knowing one of them gives us the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rethinking'></a>\n",
    "\n",
    "# Statistical Rethinking Notes and Exercises\n",
    "\n",
    "```{r}\n",
    "library(rethinking)\n",
    "\n",
    "# helper functions\n",
    "lmplot <- function(formula, model, fit.data, x.seq, plot.data,\n",
    "                   prob=.97) {\n",
    "  mu <- link(model, data=fit.data)\n",
    "  mu.mean <- apply(mu, 2, mean)\n",
    "  mu.ci <- apply(mu, 2, HPDI, prob=prob)\n",
    "  \n",
    "  h.sim <- sim(model, data=fit.data)\n",
    "  h.ci <- apply(h.sim, 2, HPDI, prob=prob)\n",
    "  \n",
    "  plot(formula, data=plot.data, col='slateblue')\n",
    "  lines(x.seq, mu.mean)\n",
    "  # confidence interval\n",
    "  lines(x.seq, mu.ci[1,], lty=2)\n",
    "  lines(x.seq, mu.ci[2,], lty=2)\n",
    "  # prediction interval\n",
    "  shade(h.ci, x.seq)\n",
    "}\n",
    "```\n",
    "\n",
    "```{r}\n",
    "get_posterior <- function(likelihood, prior) {\n",
    "  posterior <- likelihood * prior\n",
    "  posterior <- posterior / sum(posterior)\n",
    "  return(posterior)\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "# Chapter 3\n",
    "\n",
    "## Grid Approximation \n",
    "\n",
    "```{r}\n",
    "# parameter grid\n",
    "grid.size <- 1000\n",
    "\n",
    "p_grid <- seq(from=0, to=1, length.out = grid.size)\n",
    "\n",
    "# un-informative prior\n",
    "prior <- rep(1, grid.size)\n",
    "\n",
    "# binomial likelihood, 8 successes out of 15 trials, with probability given \n",
    "# by p_grid\n",
    "likelihood <- dbinom(8, size=15, prob = p_grid)\n",
    "\n",
    "posterior <- likelihood * prior\n",
    "posterior <- posterior / sum(posterior)\n",
    "\n",
    "# sample from p_grid, each paramter with probabilty specified in posterior\n",
    "samples <- sample(p_grid, prob = posterior, size=1e5, replace = TRUE)\n",
    "\n",
    "dens(samples)\n",
    "```\n",
    "\n",
    "Generating dummy data. \n",
    "\n",
    "```{r}\n",
    "# sample from binomial distribution, 10 runs, each with 9 samples, with  \n",
    "# prob of success = 0.7\n",
    "rbinom(10, size=9, prob = .6)\n",
    "\n",
    "# 1e5 simulations, 9 samples each time, use probablity from the previous samples\n",
    "w <- rbinom(1e5, size = 9, prob = samples)\n",
    "table(w) / 1e5\n",
    "\n",
    "simplehist(w)\n",
    "```\n",
    "\n",
    "## Exercises\n",
    "\n",
    "```{r}\n",
    "data(homeworkch3)\n",
    "\n",
    "# 3H1\n",
    "p.grid <- seq(0, 1, length.out = 1000)\n",
    "\n",
    "prior <- rep(1, 1000)\n",
    "\n",
    "# likelihood is obtained based on data\n",
    "no.boys = sum(birth1) + sum(birth2)\n",
    "total = length(birth1) + length(birth2)\n",
    "\n",
    "likelihood <- dbinom(no.boys, size = total, prob = p.grid)\n",
    "\n",
    "posterior <- get_posterior(likelihood, prior)\n",
    "\n",
    "plot(posterior ~ p.grid, type = 'l')\n",
    "abline(v = .5, lty = 2)\n",
    "\n",
    "p.grid[which.max(posterior)]\n",
    "```\n",
    "\n",
    "```{r}\n",
    "# 3H2\n",
    "\n",
    "s <- sample(p.grid, prob = posterior, size = 1e5, replace = TRUE)\n",
    "# dens(s)\n",
    "\n",
    "HPDI(s, prob = .5)\n",
    "HPDI(s, prob = .89)\n",
    "HPDI(s, prob = .97)\n",
    "```\n",
    "\n",
    "```{r}\n",
    "# 3H3\n",
    "\n",
    "w <- rbinom(n = 1e5, size = 200, prob = s)\n",
    "dens(w)\n",
    "abline(v=no.boys, lty=2, col='blue')\n",
    "abline(v=sum(birth1), col='red', lty=2)\n",
    "```\n",
    "\n",
    "```{r}\n",
    "# 3H4\n",
    "\n",
    "# first girl, second boy\n",
    "b0 = birth2[birth1 == 0]\n",
    "b0.sim <- rbinom(1e5, size = length(b0), prob = s)\n",
    "dens(b0.sim, adj = .1)\n",
    "abline(v=sum(b0), col='red')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 Linear Models\n",
    "\n",
    "How strong is a prior, p89 Overthinking it\n",
    "\n",
    "The amount of data implied by a prior can be computed for Gaussian posterior, \n",
    "for $\\mu \\sim \\mathcal{N}(178, 0.1)$: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sigma_{post} &= 1 / \\sqrt{n} \\\\\n",
    "\\therefore n &= 1 / \\sigma_{post}^2 \\\\\n",
    "\\ n &= 1/(0.1)^2 = 100\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## Confidence Interval, p102-106\n",
    "\n",
    "Once we have a fitted model, we draw samples from the parameter posterior \n",
    "distributions to calcluate the fitted values along a sequence of possible \n",
    "predictors. The PDF of such fitted values should mirror the PDF of parameter\n",
    "posterior distributions, i.e. more samples with values near the posterior MAP.\n",
    "\n",
    "The **link function** essentially calculates fitted values, using a model\n",
    "defined by the samples draw above. \n",
    "\n",
    "Use `rethinking::link()` to get the fitted values. The link function \n",
    "essentially uses MAP of the parameter posterior distribution to calculate\n",
    "the fitted value.\n",
    "\n",
    "Each fit in this result is a distribution of possible values (based on sample\n",
    "of parameters, say 1e4 nobs). \n",
    "\n",
    "The **mean** of this distribution is the **fitted** value. \n",
    "\n",
    "Its **HPDI** is the confidence interval band.\n",
    "\n",
    "## Prediction Interval, p107\n",
    "\n",
    "Similar to above:\n",
    "\n",
    "1. draw samples from the parameter posterior distributions. \n",
    "\n",
    "2. generate a sequence of possible predictor values for fitting.\n",
    "\n",
    "3. for each data point from 2), draw random samples from a distribution\n",
    "defined by mean of fitted value (based on MAP parameters) and model \n",
    "posterior variance.\n",
    "\n",
    "4. `rethinking::PI` or `rethinking::HPDI` of the results from 3) gives the \n",
    "prediction interval for that data point.\n",
    "\n",
    "This can be down with `rethinking::sim`.\n",
    "\n",
    "# Chapter 5\n",
    "\n",
    "Plots that help with examining multivariate models, p126:\n",
    "\n",
    "1. Predictor residual plots, outcome vs residuals\n",
    "\n",
    "2. Counterfactual plots, hold other variables constant, fit with a range of \n",
    "values for one predictor.\n",
    "\n",
    "3. Posterior prediction plots, predicted versus observed.\n",
    "\n",
    "Issues with linear regression\n",
    "\n",
    "1. Multicollinearity, correlated features, causing large intervals for \n",
    "parameter estimates.\n",
    "\n",
    "2. Post-treatment Bias\n",
    "\n",
    "3. Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6\n",
    "\n",
    "When fitting multiple models for comparison, it is important that all models\n",
    "are fitted with the same set of data. Otherwise, models fitted with less data\n",
    "will have lower information criteria values, because they are asked to predict\n",
    "less. p196\n",
    "\n",
    "## Assumptions for AIC, DIC and WAIC\n",
    "\n",
    "**AIC**, page 189\n",
    "\n",
    "1. flat prior, or overwhelmed by likelihood (data)\n",
    "\n",
    "2. The posterior distribution is approximately multivariate Gaussian\n",
    "\n",
    "3. The sample size N is much larger than the number of parameters k\n",
    "\n",
    "**DIC**, page 190\n",
    "\n",
    "1. can handle informative priors\n",
    "\n",
    "2. still rquires 2 and 3 above like AIC\n",
    "\n",
    "**WAIC**, p191\n",
    "\n",
    "* Does not require posterior distribution to be multivariate Gaussian.\n",
    "\n",
    "* Often more accurate than DIC\n",
    "\n",
    "Steps to calculate WAIC, p192 Overthinking box:\n",
    "\n",
    "1. fit model\n",
    "\n",
    "2. extract samples from model parameters\n",
    "\n",
    "3. for each smaple of parameters, create a posterior distribution, calculate\n",
    "density for each outcome. I.e. this steps calculates $Pr(y_i)$\n",
    "\n",
    "4. calculate **lppd** (log-pointwise-predictive-density), $lppd=\\sum_{i=1}^{N}log(Pr(y_i))$\n",
    "\n",
    "5. calculate the **effective number of paramters**, $p_{WAIC}=\\sum_{i=1}^{N}Var(y_i)$\n",
    "\n",
    "6. $WAIC = -2 (lppd - p_{WAIC})$\n",
    "\n",
    "Notes from solutions for 6M1:\n",
    "\n",
    "From most general to least general: WAIC, DIC, AIC. \n",
    "\n",
    "When the posterior predictive mean is a good representation of the posterior \n",
    "predictive distribution, DIC and WAIC will tend to agree. \n",
    "\n",
    "When priors are effectively flat or overwhelmed by the amount of data, the DIC \n",
    "and AIC will tend to agree.\n",
    "\n",
    "`rethinking` package's `sim.train.test` can be used to run leave one out cross\n",
    "validation. p184. See instruction in Overthinking box on page 185 on parameters\n",
    "to parallelise the simulations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kl'></a>\n",
    "##  Information Theory and Deviance\n",
    "\n",
    "From **Statistical Rethinking**\n",
    "\n",
    "**Information Entropy**: for $n$ possible events and each event $i$ has probability $p_i$, then the unique measure of uncertainty is:\n",
    "\n",
    "$$ H(p) = -\\mathbb{E}[log(p_i)] = - \\sum_{i=1}^{n}p_{i} log(p_{i}) $$\n",
    "\n",
    "**Kullback-Leibler (K-L) Divergence**: the divergence is the average difference in log probability between the target ($p$) and model ($q$). Where $p$ and $q$ are parameters of the **true model** and our estimated model respectively. In otherwords, it is defined as the **additional** entropy induced by using $q$. \n",
    "\n",
    "$$ D_{KL} = \\sum p_{i}[log(p_i) - log(q_i)] = \\sum_{i} p_i log(\\frac{p_i}{q_i}) $$\n",
    "\n",
    "**Cross Entropy**: Using a probability distribution $q$ to predict events from another distribution $p$:\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "\\ H(p, q) &= - \\sum_{i}p_i log(q_i) \\\\\n",
    "\\ D_{KL}(p, q) &= H(p, q) - H(p) \\\\\n",
    "\\ &= - \\sum_{i=1}^{n}p_{i} log(q_{i}) - \\bigg(- \\sum_{i=1}^{n}p_{i} log(p_{i})\\bigg) \\\\\n",
    "\\ &= - \\sum_{i=1}^{n}p_{i} \\big(log(q_{i}) - log(p_{i})\\big)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "However, in real world, the true model, $p$, is usually unknown. Therefore **Deviance** is defined as:\n",
    "\n",
    "$$ D(q) = - 2\\sum_{i} log(q_i) $$\n",
    "\n",
    "`R` function `-2 * logLik()` \n",
    "\n",
    "**AIC** provides an estimate of average out-of-sample deviance:\n",
    "\n",
    "$$ AIC = D_{train} + 2p $$\n",
    "\n",
    "where $p$ is the number of free parameters to be estimated in the model.\n",
    "\n",
    "** Deviance Information Criterion (DIC) ** \n",
    "\n",
    "** Widely Applicable Information Criterion **\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7\n",
    "\n",
    "\n",
    "# Chapter 8\n",
    "\n",
    "## MCMC\n",
    "\n",
    "* Samples directly from the joint posterior of a model without maximizing \n",
    "anything\n",
    "* Without Gaussian posterior assumptions\n",
    "\n",
    "## HMC\n",
    "\n",
    "* Requires continuous parameters\n",
    "* Needs to tune to a particular model and its data.\n",
    "\n",
    "* Use `rethinking::map2stan`\n",
    "* `rethinking::show` shows Deviance/DIC/WAIC for HMC the models.\n",
    "* `stancode` shows the Stan definition of models.\n",
    "* Use `plot(model)` to show **Trace Plots**. Looking for:\n",
    "  * stationarity, i.e. stable mean, and\n",
    "  * good mixing, i.e. no autocorrelation.\n",
    "* `precis(model)` shows additional metrics:\n",
    "  + `n_eff` - effective number of independent samples\n",
    "  + `Rhat` - estimate of convergence of the Markov chains to the target \n",
    "  distribution. It should approach 1.00. When this is > 1, usually it indicates\n",
    "  that the chains have not converged. 1.1 is very bad. However, **invalid** \n",
    "  chains can also approach 1.00\n",
    "  + These metrics should be used as signs of danger, but **never** proof of \n",
    "  safty.\n",
    "* Flat prior can make HMC sampling slow or even fail. Weakly informed prior \n",
    "can sometime solve the problem.\n",
    "* Often a model that is very slow to sample is **under-identified**.\n",
    "\n",
    "* Cauchy distribution has no mean or std because its fat tail. Mean and std \n",
    "do not stablize as you sample the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
